{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[41.108370423316956,\n",
       " 20.571530282497406,\n",
       " 14.869476391002536,\n",
       " 11.810149062424898,\n",
       " 9.738405927084386,\n",
       " 8.408616886474192,\n",
       " 7.5299843503162265,\n",
       " 6.718823921866715,\n",
       " 6.23967135977,\n",
       " 5.866247198544443,\n",
       " 5.510835058987141,\n",
       " 5.214978997595608,\n",
       " 5.1632670275866985,\n",
       " 5.1304777432233095,\n",
       " 5.074023054912686,\n",
       " 4.984083301387727,\n",
       " 4.962003007531166,\n",
       " 4.920343808829784,\n",
       " 4.88114814274013,\n",
       " 4.871442980132997,\n",
       " 4.765593437477946,\n",
       " 4.682630088180304,\n",
       " 4.6916457349434495,\n",
       " 4.672988479491323,\n",
       " 4.624778980854899,\n",
       " 4.667723646387458,\n",
       " 4.624619393143803,\n",
       " 4.689243713393807,\n",
       " 4.630268991459161,\n",
       " 4.592610067687929,\n",
       " 4.586607128381729,\n",
       " 4.602433471009135,\n",
       " 4.599996434524655,\n",
       " 4.637383619789034,\n",
       " 4.5791293936781585,\n",
       " 4.577101074159145,\n",
       " 4.577354641631246,\n",
       " 4.568498227279633,\n",
       " 4.57874867413193,\n",
       " 4.567052603233606,\n",
       " 4.534527392592281,\n",
       " 4.559301881119609,\n",
       " 4.559289708267897,\n",
       " 4.601690445560962,\n",
       " 4.593903873581439,\n",
       " 4.625640424899757,\n",
       " 4.586281947325915,\n",
       " 4.591703794430941,\n",
       " 4.584441194310784,\n",
       " 4.543974498752505]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.load(r'model_Denoising_AutoEncoder_4096_vgg_19_balance_state.pkl')['train_loss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Mon Jun  8 16:17:10 2020\n",
    "\n",
    "@author: 12057\n",
    "\"\"\"\n",
    "import os\n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "import pickle\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "import torch\n",
    "\n",
    "from Data_Augment_New import *\n",
    "from config import Config #获取配置\n",
    "from PIL import Image\n",
    "import PIL\n",
    "\n",
    "def glob_allfile(file_holder, file_type):\n",
    "    \"\"\"\n",
    "    获取文件夹下包括子文件夹下的固定类型的所有文件\n",
    "    :param: file_type 图片后缀名\n",
    "    :param: file_holder 目标文件夹\n",
    "    :return: all_file, 所有文件\n",
    "    \"\"\"\n",
    "    all_file = []\n",
    "    for root, dirs, files in os.walk(file_holder):\n",
    "        for file in files:\n",
    "            if os.path.splitext(file)[1] == file_type :\n",
    "                all_file.append(os.path.join(root, file))\n",
    "    return all_file\n",
    "\n",
    "def Split_train_test(img_list, isclass = 1 ,trainRatio = 0.9, randomSeed = 111):\n",
    "    \n",
    "    img_index = [isclass] * len(img_list)\n",
    "    img_list = np.array(img_list)\n",
    "    img_index = np.array(img_index)\n",
    "    \n",
    "    img_num = len(img_list)\n",
    "\n",
    "    train_num = int(img_num * trainRatio)\n",
    "    \n",
    "    index_ = list(range(img_num))\n",
    "    np.random.seed(randomSeed + isclass)\n",
    "    np.random.shuffle(index_)\n",
    "    \n",
    "    train_idx = index_[: train_num]\n",
    "    test_idx = index_[train_num: ]\n",
    "    \n",
    "    img_train = img_list[train_idx]\n",
    "    img_train_index = [isclass] * len(img_train)\n",
    "    img_test = img_list[test_idx]\n",
    "    img_test_index = [isclass] * len(img_test)\n",
    "    \n",
    "    return img_train, img_train_index, img_test, img_test_index\n",
    "\n",
    "def get_image_index(file_holder = r'./total_data0', file_type = '.png', trainRatio = 0.8 , randomSeed = 111):\n",
    "    \"\"\"\n",
    "    获得文件路径下的图片名和对应标签,并划分测试和训练集\n",
    "    \"\"\"\n",
    "    dic_class = {0:'xinguan', 1:'noxinguan'}\n",
    "    image_list0 = glob_allfile(os.path.join(file_holder, 'xin guan'), file_type)\n",
    "    image_list1 = glob_allfile(os.path.join(file_holder, 'no xinguan'), file_type)\n",
    "    \n",
    "    img_train0, img_train_index0, img_test0, img_test_index0 = Split_train_test(image_list0, isclass = 0 ,trainRatio = trainRatio, randomSeed = randomSeed)\n",
    "    img_train1, img_train_index1, img_test1, img_test_index1 = Split_train_test(image_list1, isclass = 1 ,trainRatio = trainRatio, randomSeed = randomSeed)\n",
    "\n",
    "    img_train_total = list(img_train0) + list(img_train1)\n",
    "    img_train_index_total = img_train_index0 + img_train_index1\n",
    "    idx = list(range(len(img_train_total)))\n",
    "    np.random.shuffle(idx)\n",
    "    img_train = []\n",
    "    img_train_index = []\n",
    "    for i in range(len(idx) // 2):\n",
    "        idx1 = idx[2 * i]\n",
    "        idx2 = idx[2 * i + 1]\n",
    "        img_train.append( (img_train_total[idx1], img_train_total[idx2]) )\n",
    "        img_train_index.append( int(img_train_index_total[idx1] != img_train_index_total[idx2]) )\n",
    "      \n",
    "    img_test = list(image_list0) + list(image_list1)\n",
    "    #print(len(img_test))\n",
    "    img_test_index = [0] * len(img_list0) + [1] * len(img_list1)\n",
    "    # arrayindex_train = list(range(len(img_train)))\n",
    "    # np.random.seed(randomSeed)\n",
    "    # np.random.shuffle(arrayindex_train)\n",
    "    # img_train = img_train[arrayindex_train]\n",
    "    # img_train = img_train[arrayindex_train]\n",
    "    \n",
    "    test_dataframe = pd.DataFrame(columns = ['index', 'type', 'path'])\n",
    "    for i in range(len(img_test)):\n",
    "       test_dataframe.loc[len(test_dataframe)] = [i, dic_class[img_test_index[i]], img_test[i]]\n",
    "    \n",
    "    #json_test = test_dataframe.to_json(orient = 'index')\n",
    "    #with open(r'./test_list.json', 'w') as jsonFile:\n",
    "         #jsonFile.write(json_test)\n",
    "                                           \n",
    "    return img_train, img_train_index, img_test, img_test_index, dic_class\n",
    "\n",
    "\n",
    "def normalize(tens):\n",
    "    \n",
    "    return (tens - torch.mean(tens, (1,2))) / (torch.std(tens, (1,2)) + 1e-5)\n",
    "    \n",
    "def train_loader(path, cfg, file_type = 'png'):\n",
    "    \"\"\"\n",
    "    生成loader\n",
    "    \"\"\"\n",
    "    preprocess = transforms.Compose(\n",
    "        [#自定义数据增强方法\n",
    "        #transforms.Lambda(lambda img: sidecrop(img)), #必须裁边的图像裁剪\n",
    "        #transforms.Lambda(lambda img: addblack(img)) #图像加黑边\n",
    "        ] + \\\n",
    "        [#传统数据增强\n",
    "        #transforms.RandomCrop(size = cfg.cut_size, padding = 4), #随机裁剪 + 缩放\n",
    "        #transforms.RandomHorizontalFlip(p = 0.5), #随机水平翻转\n",
    "        #transforms.RandomResizedCrop(size = cfg.resize_size[0], scale = cfg.cut_scale, ratio = cfg.cut_ratio), #随机长宽比范围裁剪,再缩放\n",
    "                                             #缩放后大小,整数    面积比例范围        长宽比比例范围\n",
    "        transforms.Resize(size = cfg.resize_size, interpolation = PIL.Image.BILINEAR), #调整大小一致，所有图片大小需要一致\n",
    "                                                          #插值方法\n",
    "        transforms.ToTensor(), #tensor化：固定操作  函数接受PIL Image或numpy.ndarray，将其先由HWC转置为CHW格式，再转为float后每个像素除以255.\n",
    "        #transforms.Lambda(lambda tens: normalize(tens)) #图像加黑边\n",
    "        ])\n",
    "    \n",
    "    path1, path2 = path\n",
    "    img1 = Image.open(path1)\n",
    "    img2 = Image.open(path2)\n",
    "    \n",
    "    img_tensor1 = preprocess(img1)\n",
    "    img_tensor2 = preprocess(img2)\n",
    "    \n",
    "    img_tensor1 = torch.tensor(img_tensor1, dtype = torch.float32)\n",
    "    img_tensor2 = torch.tensor(img_tensor2, dtype = torch.float32)\n",
    "\n",
    "    img_tensor = torch.cat((img_tensor1, img_tensor2))\n",
    "    D, H, W = list(img_tensor.shape)\n",
    "    img_tensor = img_tensor.view(1, D, H, W)\n",
    "    \n",
    "    return img_tensor\n",
    "  \n",
    "def test_loader(path, cfg, file_type = 'png'):\n",
    "    \"\"\"\n",
    "    生成loader\n",
    "    \"\"\"\n",
    "    preprocess = transforms.Compose(\n",
    "        [#自定义数据增强方法\n",
    "        #transforms.Lambda(lambda img: sidecrop(img)), #必须裁边的图像裁剪\n",
    "        #transforms.Lambda(lambda img: addblack(img)) #图像加黑边\n",
    "        ] + \\\n",
    "        [#传统数据增强\n",
    "        #transforms.RandomCrop(size = cfg.cut_size, padding = 4), #随机裁剪 + 缩放\n",
    "        #transforms.RandomHorizontalFlip(p = 0.5), #随机水平翻转\n",
    "        #transforms.RandomResizedCrop(size = cfg.resize_size[0], scale = cfg.cut_scale, ratio = cfg.cut_ratio), #随机长宽比范围裁剪,再缩放\n",
    "                                             #缩放后大小,整数    面积比例范围        长宽比比例范围\n",
    "        transforms.Resize(size = cfg.resize_size, interpolation = PIL.Image.BILINEAR), #调整大小一致，所有图片大小需要一致\n",
    "                                                          #插值方法\n",
    "        transforms.ToTensor(), #tensor化：固定操作  函数接受PIL Image或numpy.ndarray，将其先由HWC转置为CHW格式，再转为float后每个像素除以255.\n",
    "        #transforms.Lambda(lambda tens: normalize(tens)) #图像加黑边\n",
    "        ])\n",
    "    \n",
    "    img = Image.open(path)\n",
    "    \n",
    "    img_tensor = preprocess(img)\n",
    "    img_tensor = torch.tensor(img_tensor, dtype = torch.float32)\n",
    "\n",
    "    D, H, W = list(img_tensor.shape)\n",
    "    img_tensor = img_tensor.view(1, D, H, W)\n",
    "    \n",
    "    return img_tensor\n",
    "\n",
    "    \n",
    "class trainset(Dataset):\n",
    "    def __init__(self, img_train, img_train_index, cfg, loader = train_loader):\n",
    "        #定义好 image 的路径\n",
    "        self.images = img_train\n",
    "        self.target = img_train_index\n",
    "        self.cfg = cfg\n",
    "        self.loader = loader\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        fn = self.images[index]\n",
    "        img = self.loader(fn, cfg = self.cfg)\n",
    "        target = self.target[index]\n",
    "        return img,target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "\n",
    "class testset(Dataset):\n",
    "    def __init__(self, img_test, img_test_index, cfg, loader = test_loader):\n",
    "        #定义好 image 的路径\n",
    "        self.images = img_test\n",
    "        self.target = img_test_index\n",
    "        self.cfg = cfg\n",
    "        self.loader = loader\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        fn = self.images[index]\n",
    "        img = self.loader(fn, cfg = self.cfg)\n",
    "        target = self.target[index]\n",
    "        return img,target\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "def data_get(config):\n",
    "    \"\"\"\n",
    "    获取数据\n",
    "    \"\"\"\n",
    "    img_train, img_train_index, img_test, img_test_index, dic_class = get_image_index(config.data_info, '.png')\n",
    "    train_data = trainset(img_train, img_train_index, config)\n",
    "    \n",
    "    \"\"\"\n",
    "    if config.distribution: #分布式训练\n",
    "        train_sampler = torch.utils.data.distributed.DistributedSampler(train_data)\n",
    "        trainloader = DataLoader(train_data, batch_size = int(config.batch_size / cfg.distribution), shuffle = True, sampler = train_sampler)\n",
    "    else:\n",
    "        trainloader = DataLoader(train_data, batch_size = config.batch_size, shuffle = True)\n",
    "    \"\"\"\n",
    "    trainloader = DataLoader(train_data, batch_size = config.batch_size, num_workers = 0, shuffle = True)\n",
    "    test_data = testset(img_test, img_test_index, config)\n",
    "    testloader = DataLoader(test_data, batch_size = 1, shuffle = False, num_workers = 0)\n",
    "    \n",
    "    return trainloader, testloader\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Config loading begin\n",
      "\n",
      "Data: DAE_metric_data\n",
      "\n",
      "Succeed to read classes file\n",
      "Succeed to read config file\n",
      "Config loading is valid\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      " \n",
      " \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'date_get' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-3f094a0d0c62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConfig\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'config_dae_metric.yml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtestloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdate_get\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'date_get' is not defined"
     ]
    }
   ],
   "source": [
    "config = Config(r'config_dae_metric.yml')\n",
    "trainloader, testloader = date_get(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
