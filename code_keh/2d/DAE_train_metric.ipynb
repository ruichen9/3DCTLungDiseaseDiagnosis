{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Config loading begin\n",
      "\n",
      "Data: DAE_metric_data\n",
      "\n",
      "Succeed to read classes file\n",
      "Succeed to read config file\n",
      "Config loading is valid\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      " \n",
      " \n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Date getting begin\n",
      "\n",
      "Succeeded to get_data\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      " \n",
      " \n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Begin train\n",
      " \n",
      "Model use Denoising_AutoEncoder_4096_vgg_19_metric\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gpu is used\n",
      "Training time = 0.000106 s / epoch\n",
      " \n",
      "Finish train\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      " \n",
      " \n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Begin test\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gpu is used\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-51db68cd9a15>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    514\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 515\u001b[0;31m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'./config_dae_metric.yml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    516\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    517\u001b[0m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-51db68cd9a15>\u001b[0m in \u001b[0;36mmain\u001b[0;34m(config_path)\u001b[0m\n\u001b[1;32m    505\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdata_ok\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    506\u001b[0m         \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#模型训练\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 507\u001b[0;31m         \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#模型训练\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    508\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtrain_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-51db68cd9a15>\u001b[0m in \u001b[0;36mtest\u001b[0;34m(testloader, cfg)\u001b[0m\n\u001b[1;32m    465\u001b[0m            \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#变量化输入x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m            \u001b[0mencode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#前向传播\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m            \u001b[0mencode_pic\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mencode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sufedc_nvidia_newgyh/anaconda/envs/myTorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-51db68cd9a15>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpool_index_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m                 \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sufedc_nvidia_newgyh/anaconda/envs/myTorch/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/sufedc_nvidia_newgyh/anaconda/envs/myTorch/lib/python3.6/site-packages/torch/nn/modules/activation.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtanh\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Jun 16 18:11:40 2020\n",
    "\n",
    "@author: 12057\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "import sys\n",
    "sys.path.append(r'/home/sufedc_nvidia_newgyh/apex')\n",
    "from apex import amp\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn #类\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import cv2\n",
    "import PIL\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from config import Config #获取配置\n",
    "from DAE_data_loader import data_get\n",
    "\n",
    "class Denoising_AutoEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    autoencoder神经网络结构搭建\n",
    "    \"\"\"\n",
    "    cfg_conv = [[1, 64, 3, 1, 1], [64, 64, 3, 1, 1], 'M', [64, 128, 3, 1, 1], [128, 128, 3, 1, 1], 'M',\n",
    "                 [128, 256, 3, 1, 1], [256, 256, 3, 1, 1], [256, 256, 3, 1, 1], [256, 256, 3, 1, 1], 'M', \n",
    "                 [256, 512, 3, 1, 1], [512, 512, 3, 1, 1], [512, 512, 3, 1, 1], [512, 512, 3, 1, 1], 'M', \n",
    "                 [512, 512, 3, 1, 1], [512, 512, 3, 1, 1], [512, 512, 3, 1, 1], [512, 512, 3, 1, 1], 'M']\n",
    "    #encode网络架构图  conv:[inner_channels, outer_channels, filter, stride, padding]\n",
    "                      #最大池化层:M  2*2 步长2\n",
    "\n",
    "    cfg_tranconv = ['M', [512, 512, 3, 1, 1], [512, 512, 3, 1, 1], [512, 512, 3, 1, 1], [512, 512, 3, 1, 1],\n",
    "                    'M', [512, 512, 3, 1, 1], [512, 512, 3, 1, 1], [512, 512, 3, 1, 1], [512, 256, 3, 1, 1],  \n",
    "                    'M', [256, 256, 3, 1, 1], [256, 256, 3, 1, 1], [256, 256, 3, 1, 1],  [256, 128, 3, 1, 1],\n",
    "                    'M', [128, 128, 3, 1, 1], [128, 64, 3, 1, 1], 'M', [64, 64, 3, 1, 1], [64, 1, 3, 1, 1]]     #decode网络架构图  tran_conv:[inner_channels, outer_channels, filter, stride, padding]\n",
    "                     #最大逆池化层:M  2*2 步长2\n",
    "\n",
    "    pool_kernel_size = 2 #池化层核大小\n",
    "    pool_stride = 2 #池化层步长\n",
    "\n",
    "    pool_index_list = [] #池化原始所在位置list\n",
    "    \n",
    "    def __init__(self, feature_len, img_size):\n",
    "        \"\"\"\n",
    "        初始化函数\n",
    "        :param: feature_len encode长度\n",
    "        :param: img_size 图片尺寸           \n",
    "        \"\"\"\n",
    "        \n",
    "        super(Denoising_AutoEncoder, self).__init__() #等价与nn.Module.__init__()   运用nn.Module初始化\n",
    "        \n",
    "        self.img_size = img_size #图片大小\n",
    "        self.feature_len = feature_len #encode长度\n",
    "        self.in_channels = 3 #记录输入层数，用于网络输入\n",
    "        self.en_net = self.encode_conv() #encode网络\n",
    "        self.en_fc = nn.Linear(in_features = self.in_channels * self.img_size[0] * self.img_size[1], out_features = self.feature_len, bias = True) #encode最后的全连接层       \n",
    "        self.de_fc = nn.Linear(in_features = self.feature_len, out_features = self.in_channels * self.img_size[0] * self.img_size[1], bias = True) #decode最初的全连接层     \n",
    "        self.de_net = self.decode_conv() #decode网络     \n",
    "\n",
    "    def corrupt_x(self, x, cor_rate = 0.01):\n",
    "        \"\"\"\n",
    "        对于x进行随机corrupt\n",
    "        :param: x 输入变量x\n",
    "        :param: cor_rate 随机corrupt概率\n",
    "        return corrupted_x corrupt后的变量x\n",
    "        \"\"\"\n",
    "        judge_matrix = np.random.randn(*list(x.shape)) > cor_rate\n",
    "        judge_matrix = judge_matrix.astype('float32')\n",
    "        judge_matrix = torch.FloatTensor(judge_matrix)\n",
    "        try: #用gpu\n",
    "            judge_matrix = judge_matrix.cuda(x.device)\n",
    "        except: #用cpu\n",
    "            pass\n",
    "        corrupted_x = x * judge_matrix\n",
    "        \n",
    "        return corrupted_x\n",
    "    \n",
    "    def encode_conv(self):\n",
    "        \"\"\"\n",
    "        建立encode部分网络, 不用ReLU稀疏特征, 不用池化层\n",
    "        return  encode_feature_net  encode部分\n",
    "        \"\"\"\n",
    "        encode_feature_net = []\n",
    "        for layer_type in self.cfg_conv:\n",
    "            if layer_type == 'M':\n",
    "                layer = [nn.MaxPool2d(kernel_size = self.pool_kernel_size, stride = self.pool_stride, return_indices = True)]#最大池化层\n",
    "                        #对应原始所在位置 \n",
    "                self.img_size[0] = int((self.img_size[0] - self.pool_kernel_size) / self.pool_stride + 1) #计算图片大小\n",
    "                self.img_size[1] = int((self.img_size[1] - self.pool_kernel_size) / self.pool_stride + 1)#计算图片大小\n",
    "            else: #卷积层\n",
    "                in_channels, out_channels, kernel_size, stride, padding = layer_type\n",
    "                self.img_size[0] = int((self.img_size[0] - kernel_size + 2 * padding) / stride + 1) #计算图片大小\n",
    "                self.img_size[1] = int((self.img_size[1] - kernel_size + 2 * padding) / stride + 1)#计算图片大小\n",
    "                layer = [nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding), #卷积层\n",
    "                                  #输入通道数     输出特征数    卷积核大小    步长    填充\n",
    "                         nn.BatchNorm2d(num_features = out_channels), #BN层\n",
    "                                             #特征数\n",
    "                         nn.Tanh()]  #Tanh层 \n",
    "                         #inplace=True改变输入的数据, 节省内存\n",
    "                self.in_channels = out_channels\n",
    "                \n",
    "            encode_feature_net += layer\n",
    "                  \n",
    "        return nn.Sequential(*encode_feature_net)\n",
    "    \n",
    "    \n",
    "    def decode_conv(self):\n",
    "        \"\"\"\n",
    "        建立decode部分网络, 不用ReLU稀疏特征, 不用逆池化层\n",
    "        return  decode_pic_net  encode部分\n",
    "        \"\"\"\n",
    "        decode_pic_net = []\n",
    "        for layer_type in self.cfg_tranconv:\n",
    "            if layer_type == 'M':\n",
    "                layer = [nn.MaxUnpool2d(kernel_size = self.pool_kernel_size, stride = self.pool_stride)]#最大逆池化层\n",
    "            else: #卷积层\n",
    "                in_channels, out_channels, kernel_size, stride, padding = layer_type\n",
    "                layer = [nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding), #卷积层\n",
    "                                  #输入通道数     输出特征数    卷积核大小    步长    填充\n",
    "                         nn.BatchNorm2d(num_features = out_channels), #BN层\n",
    "                                             #特征数\n",
    "                         nn.Tanh()]  #Tanh层 \n",
    "                         #inplace=True改变输入的数据, 节省内存\n",
    "                #self.in_channels = out_channels\n",
    "                \n",
    "            decode_pic_net += layer\n",
    "        decode_pic_net[-1] = nn.Sigmoid() #最后一层改成Sigmoid 让输入为0-1之间\n",
    "            \n",
    "        return nn.Sequential(*decode_pic_net)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        前向传播\n",
    "        :param: x 图片变量\n",
    "        return code: 图片encode编码 \n",
    "               decode: encode编码 decode结果\n",
    "        \"\"\"\n",
    "        \n",
    "        code = self.corrupt_x(x) #corrupt_x\n",
    "        for net in self.en_net: #encode部分\n",
    "            if isinstance(net, nn.MaxPool2d):\n",
    "                code, pool_index = net(code)  #获取池化位置\n",
    "                self.pool_index_list.append(pool_index)\n",
    "            else:\n",
    "                code = net(code)\n",
    "                \n",
    "        code = code.view(code.size(0), -1)\n",
    "        code = self.en_fc(code)\n",
    "        \n",
    "        decode = self.de_fc(code)\n",
    "        decode = decode.view(decode.size(0), self.in_channels, self.img_size[0], self.img_size[1])\n",
    "        \n",
    "        for net in self.de_net: #decode部分\n",
    "            if isinstance(net, nn.MaxUnpool2d):\n",
    "                decode = net(decode, self.pool_index_list.pop())\n",
    "            else:\n",
    "                decode = net(decode)\n",
    "        \n",
    "        return code, decode\n",
    "\n",
    "    def encode_data(self, x):\n",
    "        code = x \n",
    "        for net in self.en_net: #encode部分\n",
    "            if isinstance(net, nn.MaxPool2d):\n",
    "                code, pool_index = net(code)  #获取池化位置\n",
    "                self.pool_index_list.append(pool_index)\n",
    "            else:\n",
    "                code = net(code)\n",
    "                \n",
    "        code = code.view(code.size(0), -1)\n",
    "        code = self.en_fc(code)\n",
    "        \n",
    "        return code\n",
    "    \n",
    "def get_data(cfg):\n",
    "    \"\"\"\n",
    "    获取预处理和数据增强后的数据集\n",
    "    :param: cfg 配置文件\n",
    "    return trainloader, testloader, data_ok\n",
    "           训练loader   测试loader  数据是否获得\n",
    "    \"\"\"\n",
    "    print('>' * 80)\n",
    "    print('Date getting begin')\n",
    "    print('')\n",
    "    \n",
    "    try: \n",
    "        #训练集数据获取\n",
    "        \n",
    "        #训练集数据预处理\n",
    "        trainloader, testloader = data_get(cfg) \n",
    "\n",
    "        print('Succeeded to get_data')\n",
    "        print('>' * 80)\n",
    "        print(' ')\n",
    "        print(' ')\n",
    "        \n",
    "        return trainloader, testloader, True \n",
    "    \n",
    "    except: #防爆\n",
    "        \n",
    "        print('Failed to get_data, stop training')\n",
    "        print('>' * 80)\n",
    "        print(' ')\n",
    "        print(' ')\n",
    "        \n",
    "        return None, None, False\n",
    "    \n",
    "\"\"\"\n",
    "通用模型初始化\n",
    "\"\"\"\n",
    "def initialize_weights(model):\n",
    "    \"\"\"\n",
    "    模型初始化\n",
    "    :param:model 输入模型 可以用model.apply(initialize_weights)调用\n",
    "    \"\"\"\n",
    "    for module in model.modules(): #模型中的所有模式，包含总，序列，层\n",
    "        \n",
    "        if isinstance(module, nn.Conv2d): #卷积层\n",
    "            n_conv = module.kernel_size[0] * module.kernel_size[1] * module.out_channels #卷积权重元素个数\n",
    "            module.weight.data.normal_(0, math.sqrt(2. / n_conv)) #卷积核初始化 正态随机数, 限制标准差\n",
    "            if module.bias is not None: #有偏移项\n",
    "                module.bias.data.zero_() #偏移项初始化 = 0\n",
    "                \n",
    "        elif isinstance(module, nn.BatchNorm2d): #BN层\n",
    "            module.weight.data.fill_(1) #归一化权重 == 标准差, 初始化 = 1\n",
    "            module.bias.data.zero_() #归一化偏移项 == 均值, 初始化 = 0\n",
    "            \n",
    "        elif isinstance(module, nn.Linear): #全连接层\n",
    "            n_fc = module.in_features * module.out_features #全连接层权重个数\n",
    "            module.weight.data.normal_(0, math.sqrt(2. / n_fc)) #全连接权重正态初始化\n",
    "            module.bias.data.zero_()#偏移项初始化 = 0\n",
    "            \n",
    "        elif isinstance(module, nn.ConvTranspose2d): #反卷积层\n",
    "            n_conv = module.kernel_size[0] * module.kernel_size[1] * module.out_channels #卷积权重元素个数\n",
    "            module.weight.data.normal_(0, math.sqrt(2. / n_conv)) #卷积核初始化 正态随机数, 限制标准差\n",
    "            if module.bias is not None: #有偏移项\n",
    "                module.bias.data.zero_() #偏移项初始化 = 0\n",
    "\n",
    "                \n",
    "def Contrastive_Loss(encode1, encode2, not_same, margin_rate = 0.01):\n",
    "    size =  encode1.shape[1]\n",
    "    #print(size)\n",
    "    margin = size * margin_rate\n",
    "    euclidean_distance = torch.nn.PairwiseDistance()(encode1, encode2)\n",
    "    contrastive_loss = torch.mean((1 - not_same) * torch.pow(euclidean_distance, 2) +     # calmp夹断用法\n",
    "                        (not_same) * torch.pow(torch.clamp(margin - euclidean_distance, min = 0.0), 2))     \n",
    "    \n",
    "    return contrastive_loss / size\n",
    " \n",
    "#模型训练\n",
    "def train(trainloader, cfg):\n",
    "    \"\"\"\n",
    "    :param: trainloader 训练数据loader\n",
    "    :param: cfg 配置文件\n",
    "    return train_loss 各epoch训练损失函数list\n",
    "    \"\"\"\n",
    "    print('>' * 80)    \n",
    "    print('Begin train')\n",
    "    print(' ')\n",
    "\n",
    "    #模型基本配置\n",
    "    print('Model use {}'.format(cfg.model_name))\n",
    "    print(' ')\n",
    "    \n",
    "    model = Denoising_AutoEncoder(cfg.classes_num, list(cfg.resize_size)) #载入模型\n",
    "\n",
    "    begin_epoch = 0 #初始epoch\n",
    "    if cfg.pretrain: #如果有预训练\n",
    "        model_info = torch.load(os.path.join(cfg.pretrain, 'model_{}_state.pkl'.format(cfg.model_name)))\n",
    "        model.load_state_dict(model_info['state_dict']) #加载训练出的模型\n",
    "        begin_epoch = model_info['epoch'] + 1\n",
    "\n",
    "    model.train() #切换到训练模式\n",
    "          \n",
    "    device = torch.device(cfg.device) #选择设备\n",
    "    try: #有gpu\n",
    "        model.cuda(device) #设备选择\n",
    "        gpu = True #是否有gpu\n",
    "        print('Gpu is used')\n",
    "    except:#不用gpu\n",
    "        gpu = False\n",
    "        print('Cpu is used')\n",
    "    \n",
    "    criterion = torch.nn.MSELoss() #损失函数方法：MSE\n",
    "    alpha = cfg.alpha if not cfg.pretrain else model_info['alpha'] #初始学习率，有预处理以预处理为准\n",
    "    optimizer = torch.optim.SGD(model.parameters(), momentum = cfg.momentum, lr = alpha, weight_decay = cfg.weight_decay) #迭代方法SGD\n",
    "                                                           #动量              初始学习率            权重衰减趋势\n",
    "    #optimizer = torch.optim.Adam(model.parameters(), lr = 0.001, betas = (0.9, 0.999), eps = 1e-8, weight_decay = cfg.weight_decay) #迭代方法Adam\n",
    "                                                       #学习率      梯度及梯度平方系数   分母防零修正           权重衰减系数\n",
    "                                                       \n",
    "    #scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = 10) #学习率衰减(余弦退火)\n",
    "                                                        #0, T_max下降，T_max到2 * T_max上升\n",
    "    #scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer,lr_lambda = lambda step:np.sin(step) / step) #自己设定,函数输入为步数\n",
    "                                                                    #自己设定函数\n",
    "    #scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones = [20, 80], gamma = 0.9) #分段式衰减\n",
    "                                                                #设定变化点，遇到该点变化  衰减系数\n",
    "    #scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.99) #指数衰减，每个epoch\n",
    "                                                                   #衰减系数\n",
    "    #scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode = 'min', factor = 0.1, patience = 10, verbose = False, threshold = 0.0001, threshold_mode = 'rel', cooldown = 0, min_lr = 0, eps = 1e-08) #自适应\n",
    "                                                                     #检测loss减小     衰减系数       容忍次数        是否print         变化阈值范围        rel比例 abs值           冷却时间      最小lr     效果较差不变                                  \n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = cfg.lr_step, gamma = cfg.lr_decay) #学习率线性衰减\n",
    "                                                                 #衰减步长         衰减系数 lr *= lr_decay\n",
    "    if not cfg.pretrain: #如果没预训练\n",
    "        model.apply(initialize_weights) #模型初始化，内置初始化，均匀分布\n",
    "    \n",
    "    if gpu:\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level = \"O1\", verbosity = 0) #混合精度模型\n",
    "                                              #Oo fp32, O1混合, O2几乎fp16, O3 fp16  \n",
    "    if cfg.distribution:\n",
    "        model = torch.nn.DataParallel(model, device_ids = list(range(cfg.distribution)))\n",
    "        \n",
    "    if cfg.pretrain: #如果预训练\n",
    "        train_loss = model_info['train_loss']\n",
    "    else:\n",
    "        train_loss = []\n",
    "    \n",
    "    total_start_time = time.time() #记录时间\n",
    "    start_time = time.time() #记录时间\n",
    "    \n",
    "    for epoch in tqdm(range(begin_epoch, cfg.epoch_num)): #迭代全图\n",
    "    #for epoch in range(1, cfg.epoch_num + 1): #迭代全图  \n",
    "        \n",
    "        train_loss_i = 0 #第i次epoch损失\n",
    "        train_loss_dae = 0\n",
    "        train_loss_metric = 0\n",
    "        for batch_idx, (imgs, not_same) in enumerate(trainloader): #迭代批次\n",
    "            #批数       图片   标签\n",
    "            \n",
    "            #one-hot label 化：(交叉熵里面自动有)\n",
    "            #classes = torch.zeros(cfg.batch_size, len(cfg.classes)).scatter_(1, classes.view(len(classes),1), 1)\n",
    "                                                                     #稀疏化 维度       值                  对应标签值           \n",
    "            if gpu: #用gpu\n",
    "                imgs = imgs.cuda(device) #将数据移到GPU上\n",
    "                not_same = not_same.cuda(device)\n",
    "                inputs= Variable(imgs)  #变量化输入x,y\n",
    "             \n",
    "            optimizer.zero_grad()   # 先将optimizer梯度先置为0\n",
    "            encode1, decode1 = model(inputs[:,:,0,:,:]) #前向传播\n",
    "            encode2, decode2 = model(inputs[:,:,1,:,:]) #前向传播\n",
    "            #outputs = model.forward(inputs) #等价效果\n",
    "            loss_dae = (criterion(inputs[:,:,0,:,:], decode1) + criterion(inputs[:,:,1,:,:], decode2))/2\n",
    "            loss_metric = Contrastive_Loss(encode1, encode2, not_same)\n",
    "            loss = loss_dae + 0.1 * loss_metric\n",
    "            #loss = loss_metric\n",
    "            #损失函数\n",
    "\n",
    "            if gpu:\n",
    "                with amp.scale_loss(loss, optimizer) as scaled_loss:#采用混合精度模型         \n",
    "                    scaled_loss.backward() \n",
    "            else:\n",
    "                loss.backward()  #反向传播，计算梯度\n",
    "            \n",
    "            optimizer.step() #更新参数\n",
    "        \n",
    "            train_loss_i += loss.data.item()#记录每次训练Loss, 必须loss.data[0]\n",
    "            train_loss_dae += loss_dae.data.item()\n",
    "            train_loss_metric += loss_metric.data.item()\n",
    "            \n",
    "        #print(train_loss_dae)\n",
    "        #print(train_loss_metric * 0.1)\n",
    "        \n",
    "        scheduler.step() #学习率记录step      \n",
    "        train_loss.append(train_loss_i) #记录每轮的损失函数值\n",
    "        \n",
    "        if  epoch % 5 == 4: #每5次迭代            \n",
    "            end_time = time.time() #记录时间\n",
    "            \n",
    "            #展示模型训练状态\n",
    "            print(' ')\n",
    "            print('>' * 80)    \n",
    "            print('Epoch : {} - {}'.format(epoch - 3, epoch + 1))\n",
    "            print('Training_time = {} s / epoch'.format(str( (end_time - start_time) / 5 )[:8]) )\n",
    "            print('Avg_loss_function = {}'.format(np.mean(train_loss[-5:])))\n",
    "            print('>' * 80)\n",
    "            print(' ')\n",
    "            \n",
    "            if not cfg.mix_up and epoch / cfg.epoch_num > 0.1: #预热10%迭代\n",
    "                torch.save({'epoch': epoch, 'state_dict': model.state_dict(), \n",
    "                            'train_loss': train_loss, 'alpha': optimizer.state_dict()['param_groups'][0]['lr']}, #记录迭代次数，状态字典，最好结果, 损失函数list, 学习率\n",
    "                            os.path.join(cfg.save_path, 'model_{}_state.pkl'.format(cfg.model_name))) #最好的结果(覆盖原来的)\n",
    "                \n",
    "                #torch.save(model.state_dict(), os.path.join(cfg.save_path, 'model_{}_state.pkl'.format(cfg.model_name))) #最好的结果(覆盖原来的)\n",
    "                #保存中间最好的模型(以后可以再训练) 保存模型所有信息，读取时要载入框架\n",
    "                #torch.save(model, './model_{}.pkl'.format(cfg.model_name)) #保存模型信息，读取时直接读取 等价\n",
    "\n",
    "            start_time = time.time() #更新时间\n",
    "            \n",
    "        torch.cuda.empty_cache() #清理显存\n",
    "         \n",
    "    total_end_time = time.time() #记录时间           \n",
    "    \n",
    "    print('Training time = {} s / epoch'.format( str( (total_end_time - total_start_time) / cfg.epoch_num )[:8] ) )\n",
    "    print(' ')\n",
    "    print('Finish train')\n",
    "    print('>' * 80)    \n",
    "    print(' ')\n",
    "    print(' ')\n",
    "    \n",
    "    return train_loss\n",
    "\n",
    "    \n",
    "#模型测试\n",
    "def test(testloader, cfg):\n",
    "    \"\"\"\n",
    "    测试Auto_encoder效果\n",
    "    :param: testloader 测试数据loader\n",
    "    :param: cfg 配置文件\n",
    "    return: precision 准确率\n",
    "    \"\"\"\n",
    "    print('>' * 80)\n",
    "    print('Begin test')\n",
    "    print(' ')\n",
    "    \n",
    "    dic_class = {0: 'xinguan', 1: 'noxinguan'}\n",
    "    if not os.path.exists(os.path.join(cfg.save_path, 'dae_metric_result')):\n",
    "        os.mkdir(os.path.join(cfg.save_path, 'dae_metric_result'))\n",
    "        for key in dic_class:\n",
    "            os.mkdir(os.path.join(cfg.save_path, 'dae_metric_result', dic_class[key]))\n",
    "        \n",
    "    #载入模型结构   \n",
    "    model = Denoising_AutoEncoder(cfg.classes_num, list(cfg.resize_size)) #载入模型\n",
    "    \n",
    "    model_info = torch.load(os.path.join(cfg.save_path, 'model_{}_state.pkl'.format(cfg.model_name))) #获取字典\n",
    "    model.load_state_dict(model_info['state_dict']) #加载训练出的模型\n",
    "    \n",
    "    #model.load_state_dict(torch.load(os.path.join(cfg.save_path, 'model_{}_state.pkl'.format(cfg.model_name)))) #加载训练出的模型\n",
    "    #model = torch.load(r'./model_{}.pkl'.format(cfg.model_name)) 等价\n",
    "    \n",
    "    model.eval() #测试，不改变权重\n",
    "\n",
    "    device = torch.device(cfg.device) #选择设备\n",
    "    try: #用gpu\n",
    "        model.cuda(device) #设备选择\n",
    "        gpu = True #是否有gpu\n",
    "        print('Gpu is used')\n",
    "    except:#不用gpu\n",
    "        gpu = False\n",
    "        print('Cpu is used')\n",
    "    \n",
    "    total = 0 #图片总数\n",
    "\n",
    "    with torch.no_grad(): #不进行反向传播, 减少内存\n",
    "    \n",
    "        start_time = time.time() #记录时间\n",
    "        \n",
    "        for idx, (imgs, classes) in enumerate(testloader): #遍历图片\n",
    "           #索引  图片  \n",
    "           if gpu:#用gpu\n",
    "               imgs= imgs.cuda(device)   # 将数据移到GPU上\n",
    "           inputs = Variable(imgs) #变量化输入x\n",
    "           \n",
    "           encode, decode = model(inputs[:,:,0,:,:]) #前向传播\n",
    "           \n",
    "           encode_pic = encode.cpu().numpy()[0, :]\n",
    "           classes = int(classes.cpu().numpy())\n",
    "           encode_size = int(np.sqrt(len(encode_pic)))\n",
    "           encode_pic = np.reshape(encode_pic, (encode_size, encode_size))\n",
    "\n",
    "           np.save(os.path.join(cfg.save_path, 'dae_metric_result', dic_class[classes], str(idx) + '.npy'), encode_pic)\n",
    "           #with open(os.path.join(cfg.save_path, 'dae_result', dic_class[classes], str(idx) + '.pkl'), 'wb') as pkl:\n",
    "                #pickle.dump(encode_pic, pkl)\n",
    "\n",
    "           #dec_pic = transforms.ToPILImage()(decode.cpu()[0, :, :, :])       \n",
    "           #dec_pic.save(os.path.join(cfg.save_path, 'ae_result', str(idx) + '.png')) #等价方法\n",
    "           \n",
    "           total += 1\n",
    "        \n",
    "        end_time = time.time()\n",
    "             \n",
    "        torch.cuda.empty_cache() #清理显存\n",
    "    \n",
    "    print('Encoding time = {} s / pic'.format( str( (end_time - start_time) / total )[:8] ) )\n",
    "    print(' ')\n",
    "    print('Finish test')\n",
    "    print('>' * 80)    \n",
    "    print(' ')\n",
    "    print(' ')\n",
    "        \n",
    "    \n",
    "    \n",
    "def main(config_path = r'./config_ae.yml'):\n",
    "    \"\"\"\n",
    "    主函数, 完成数据载入和模型训练 + 测试\n",
    "    :param: config_path config路径\n",
    "    return: train_loss,        precision,       wronglist       \n",
    "            各epcoh下训练损失   测试准确性       错判断序号列表\n",
    "    \"\"\"\n",
    "    cfg = Config(config_path) #获取配置文件\n",
    "    trainloader, testloader, data_ok = get_data(cfg) #获取数据并进行数据预处理和增强\n",
    "    if data_ok:\n",
    "        train_loss = train(trainloader, cfg) #模型训练\n",
    "        test(testloader, cfg) #模型训练\n",
    "        return train_loss\n",
    "    \n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":        \n",
    "    train_loss = main(r'./config_dae_metric.yml')\n",
    "    while True:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4006.6907)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encode1 = torch.randn((4,4096))\n",
    "encode2 = torch.randn((4,4096))\n",
    "margin_rate = 0.5\n",
    "not_same = torch.tensor([1,1,1,1])\n",
    "size = encode1.shape[0] * encode1.shape[1]\n",
    "#print(size)\n",
    "margin = size * margin_rate\n",
    "euclidean_distance = torch.nn.PairwiseDistance()(encode1, encode2)\n",
    "contrastive_loss = torch.mean((1 - not_same) * torch.pow(euclidean_distance, 2) +     # calmp夹断用法\n",
    "                    (not_same) * torch.pow(torch.clamp(margin - euclidean_distance, min = 0.0), 2))     \n",
    "c = contrastive_loss / size\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([65635656., 65647276., 65643480., 65656084.])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(not_same) * torch.pow(torch.clamp(margin - euclidean_distance, min = 0.0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([8101.5835, 8102.3008, 8102.0664, 8102.8442])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.clamp(margin - euclidean_distance, min = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([90.4164, 89.6990, 89.9337, 89.1557])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidean_distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "163.84"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.01*4*4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myTorch",
   "language": "python",
   "name": "mytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
