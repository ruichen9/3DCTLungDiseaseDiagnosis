{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Bad key \"text.kerning_factor\" on line 4 in\n",
      "/home/sufedc_nvidia_newgyh/anaconda/envs/myTorch/lib/python3.6/site-packages/matplotlib/mpl-data/stylelib/_classic_test_patch.mplstyle.\n",
      "You probably need to get an updated matplotlibrc file from\n",
      "https://github.com/matplotlib/matplotlib/blob/v3.1.3/matplotlibrc.template\n",
      "or from the matplotlib source distribution\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Config loading begin\n",
      "\n",
      "Data: dae_metric_result\n",
      "\n",
      "Succeed to read classes file\n",
      "Succeed to read config file\n",
      "Config loading is valid\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      " \n",
      " \n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Date getting begin\n",
      "\n",
      "Succeeded to get_data\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      " \n",
      " \n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Begin train\n",
      " \n",
      "Model use LeNet\n",
      " \n",
      "Gpu is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 5/25 [01:18<05:25, 16.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Epoch : 1 - 5\n",
      "Training_time = 15.73559 s / epoch\n",
      "Avg_loss_function = 9.524625724554062\n",
      "Precision = 88.18541548897683 %\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 10/25 [02:25<03:27, 13.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Epoch : 6 - 10\n",
      "Training_time = 13.27843 s / epoch\n",
      "Avg_loss_function = 5.919659465551376\n",
      "Precision = 92.7784058790277 %\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 15/25 [03:31<02:12, 13.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Epoch : 11 - 15\n",
      "Training_time = 13.27493 s / epoch\n",
      "Avg_loss_function = 3.643630728125572\n",
      "Precision = 96.89089881288864 %\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 20/25 [04:36<01:05, 13.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Epoch : 16 - 20\n",
      "Training_time = 13.09301 s / epoch\n",
      "Avg_loss_function = 2.7180150598287582\n",
      "Precision = 97.55511588468062 %\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      " \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 25/25 [05:42<00:00, 13.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Epoch : 21 - 25\n",
      "Training_time = 13.17511 s / epoch\n",
      "Avg_loss_function = 1.9282993078231812\n",
      "Precision = 99.25098925946862 %\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      " \n",
      "Training time = 13.71274 s / epoch\n",
      " \n",
      "Finish train\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      " \n",
      " \n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Begin test\n",
      " \n",
      "Gpu is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Infering time = 0.006958 s / pic\n",
      " \n",
      "Finish test\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      " \n",
      " \n",
      "Test Precision = 97.08121827411168 %\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-9ae22965cf30>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    384\u001b[0m     \u001b[0mtrain_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwronglist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mr'./config_cnn_dae.yml'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m         \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat Mar 14 20:09:47 2020\n",
    "\n",
    "@author: 12057\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "sys.path.append(r'/home/sufedc_nvidia_newgyh/apex')\n",
    "from apex import amp\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "import PIL\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from config import Config #获取配置\n",
    "from Pytorch_nets_channel1 import * #自定义的神经网络\n",
    "from Data_Augment_New import * #自定义的数据增强方法 对PIL Image\n",
    "from CV_tricks import * #自定义的CV的tricks\n",
    "from Data_loader2d import  data_get\n",
    "\n",
    "\"\"\"\n",
    "epoch: 全部图片迭代一次\n",
    "iteration: 一个batch迭代一次\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#获取数据，并进行预处理和数据增强\n",
    "\n",
    "def get_data(cfg):\n",
    "    \"\"\"\n",
    "    获取预处理和数据增强后的数据集\n",
    "    :param: cfg 配置文件\n",
    "    return trainloader, testloader, data_ok\n",
    "           训练loader   测试loader  数据是否获得\n",
    "    \"\"\"\n",
    "    print('>' * 80)\n",
    "    print('Date getting begin')\n",
    "    print('')\n",
    "    \n",
    "    try:\n",
    "        trainloader, testloader = data_get(cfg)\n",
    "            \n",
    "        print('Succeeded to get_data')\n",
    "        print('>' * 80)\n",
    "        print(' ')\n",
    "        print(' ')\n",
    "        \n",
    "        return trainloader, testloader, True \n",
    "    \n",
    "    except: #防爆\n",
    "        \n",
    "        print('Failed to get_data, stop training')\n",
    "        print('>' * 80)\n",
    "        print(' ')\n",
    "        print(' ')\n",
    "        \n",
    "        return None, None, False\n",
    "           \n",
    "\n",
    "#模型训练\n",
    "\n",
    "def train(trainloader, cfg):\n",
    "    \"\"\"\n",
    "    :param: trainloader 训练数据loader\n",
    "    :param: cfg 配置文件\n",
    "    return train_loss 各epoch训练损失函数list\n",
    "    \"\"\"\n",
    "    print('>' * 80)    \n",
    "    print('Begin train')\n",
    "    print(' ')\n",
    "\n",
    "    #模型基本配置\n",
    "    print('Model use {}'.format(cfg.model_name))\n",
    "    print(' ')\n",
    "    model = get_model(cfg.model_name, cfg.classes, attention = cfg.attention) #根据模型名载入模型\n",
    "    \n",
    "    begin_epoch = 0 #初始epoch\n",
    "\n",
    "    model.train() #切换到训练模式\n",
    "      \n",
    "    if not cfg.distribution:\n",
    "        #device = torch.device(cfg.device) #选择设备\n",
    "        try: #有gpu\n",
    "            #model.cuda(device) #设备选择\n",
    "            model.cuda()\n",
    "            gpu = True #是否有gpu\n",
    "            print('Gpu is used')\n",
    "        except:#不用gpu\n",
    "            gpu = False\n",
    "            print('Cpu is used')\n",
    "    else:\n",
    "        gpu = True #是否有gpu\n",
    "        print('Gpu is used')\n",
    "\n",
    "    if cfg.pretrain: #如果有预训练\n",
    "        model_info = torch.load(os.path.join(cfg.pretrain, 'model_{}_state.pkl'.format(cfg.model_name)))\n",
    "        \n",
    "    criterion = torch.nn.CrossEntropyLoss() #损失函数方法：交叉熵（自带softmax）\n",
    "    alpha = cfg.alpha if not cfg.pretrain else model_info['alpha'] #初始学习率，有预处理以预处理为准\n",
    "    optimizer = torch.optim.SGD(model.parameters(), momentum = cfg.momentum, lr = alpha, weight_decay = cfg.weight_decay) #迭代方法SGD\n",
    "                                                           #动量              初始学习率            权重衰减趋势\n",
    "    #optimizer = torch.optim.Adam(model.parameters(), lr = 0.001, betas = (0.9, 0.999), eps = 1e-8, weight_decay = cfg.weight_decay) #迭代方法Adam\n",
    "                                                       #学习率      梯度及梯度平方系数   分母防零修正           权重衰减系数\n",
    "                                                       \n",
    "    #scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = 10) #学习率衰减(余弦退火)\n",
    "                                                        #0, T_max下降，T_max到2 * T_max上升\n",
    "    #scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer,lr_lambda = lambda step:np.sin(step) / step) #自己设定,函数输入为步数\n",
    "                                                                    #自己设定函数\n",
    "    #scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones = [20, 80], gamma = 0.9) #分段式衰减\n",
    "                                                                #设定变化点，遇到该点变化  衰减系数\n",
    "    #scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.99) #指数衰减，每个epoch\n",
    "                                                                   #衰减系数\n",
    "    #scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode = 'min', factor = cfg.lr_decay, patience = 5, verbose = False, threshold = 0.0001, threshold_mode = 'rel', cooldown = 0, min_lr = 0, eps = 1e-08) #自适应\n",
    "                                                                     #检测loss减小            衰减系数       容忍次数        是否print         变化阈值范围        rel比例 abs值           冷却时间      最小lr  效果较差不变                                  \n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = cfg.lr_step, gamma = cfg.lr_decay) #学习率线性衰减\n",
    "                                                                #衰减步长         衰减系数 lr *= lr_decay\n",
    "    if not cfg.pretrain: #如果预训练\n",
    "        model.apply(initialize_weights) #模型初始化，内置初始化，均匀分布\n",
    "    \n",
    "    if gpu:\n",
    "        model.cuda()\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level = \"O1\", verbosity = 0) #混合精度模型\n",
    "                                              #Oo fp32, O1混合, O2几乎fp16, O3 fp16   \n",
    "    if cfg.distribution:\n",
    "        model = torch.nn.DataParallel(model, device_ids = list(cfg.distribution))\n",
    "        \n",
    "    if cfg.pretrain: #如果有预训练\n",
    "        model_info = torch.load(os.path.join(cfg.pretrain, 'model_{}_state.pkl'.format(cfg.model_name)))\n",
    "        model.load_state_dict(model_info['state_dict']) #加载训练出的模型\n",
    "        begin_epoch = model_info['epoch'] + 1        \n",
    "        if not cfg.mix_up:\n",
    "            best_correct = model_info['best_correct']\n",
    "        train_loss = model_info['train_loss']\n",
    "    else:\n",
    "        best_correct = 0 #最优的正确数\n",
    "        train_loss = []\n",
    "    \n",
    "    total_start_time = time.time() #记录时间\n",
    "    start_time = time.time() #记录时间\n",
    "    \n",
    "    for epoch in tqdm(range(begin_epoch, cfg.epoch_num)): #迭代全图\n",
    "    #for epoch in range(1, cfg.epoch_num + 1): #迭代全图  \n",
    "        correct = 0 #正确的图片数量  \n",
    "        total = 0 #图片总数\n",
    "        \n",
    "        train_loss_i = 0 #第i次epoch损失\n",
    "        for batch_idx, (imgs, classes) in enumerate(trainloader): #迭代批次\n",
    "            #批数       图片    类别 \n",
    "            \n",
    "            #one-hot label 化：(交叉熵里面自动有)\n",
    "            #classes = torch.zeros(cfg.batch_size, len(cfg.classes)).scatter_(1, classes.view(len(classes),1), 1)\n",
    "                                                                   #稀疏化 维度       值                  对应标签值           \n",
    "            \n",
    "            if cfg.mix_up:  #mix_up策略\n",
    "                imgs, classes_a, classes_b, lam = mix_up_data(imgs, classes)  #非one-hot label数据mix-up\n",
    "                if gpu: #用gpu\n",
    "                    imgs, classes_a, classes_b = imgs.cuda(), classes_a.cuda(), classes_b.cuda() #将数据移到GPU上          \n",
    "                inputs, targets_a, targets_b = Variable(imgs), Variable(classes_a),  Variable(classes_b) #变量化输入x,y_a,y_b\n",
    "                \"\"\"\n",
    "                imgs, classes = mix_up_onehot_data(imgs, classes) #one-hot label数据mix-up\n",
    "                if gpu: #用gpu\n",
    "                    imgs, classes = imgs.cuda(), classes.cuda() #将数据移到GPU上\n",
    "                inputs, targets = Variable(imgs), Variable(classes)  #变量化输入x,y\n",
    "                \"\"\"\n",
    "            else: #没用mix_up策略\n",
    "                if gpu: #用gpu\n",
    "                    imgs, classes = imgs.cuda(), classes.cuda() #将数据移到GPU上\n",
    "                inputs, targets = Variable(imgs), Variable(classes)  #变量化输入x,y\n",
    "         \n",
    "            optimizer.zero_grad()   # 先将optimizer梯度先置为0\n",
    "            \n",
    "            outputs = model(inputs) #前向传播\n",
    "            #outputs = model.forward(inputs) #等价效果\n",
    "            \n",
    "            if cfg.mix_up: #如果mix_up\n",
    "                loss = lam * criterion(outputs, targets_a) + (1 - lam) * criterion(outputs, targets_b) # 计算mix-up损失函数\n",
    "            else: #如果没mix_up\n",
    "                loss = criterion(outputs, targets) #损失函数\n",
    "                \n",
    "            #loss = criterion(outputs, targets)\n",
    "            \n",
    "            if gpu:\n",
    "                with amp.scale_loss(loss, optimizer) as scaled_loss:#采用混合精度模型         \n",
    "                    scaled_loss.backward() \n",
    "            else:\n",
    "                loss.backward()  #反向传播，计算梯度\n",
    "            #loss.backward()  #反向传播，计算梯度\n",
    "            \n",
    "            optimizer.step() #更新参数\n",
    "        \n",
    "            train_loss_i += loss.data.item()#记录每次训练Loss, 必须loss.data[0]\n",
    "            \n",
    "            if not cfg.mix_up: #没有mix_up下才有中间结果\n",
    "                _, predicted = torch.max(outputs.data, dim = 1) #获得预测结果，结果为批次数据, 所以行最大(一行一个结果)\n",
    "                correct += predicted.eq(targets.data).cpu().sum().item() #计算正确的图片数，cpu上算,.tensor.item()获取值\n",
    "                \n",
    "            total += inputs.size(0)#图片数加总(size第一维为批大小), size为大小\n",
    "        \n",
    "        scheduler.step() #学习率记录step      \n",
    "        train_loss.append(train_loss_i) #记录每轮的损失函数值\n",
    "        precision = 100. * correct / total #准确率 \n",
    "    \n",
    "        if  epoch % 5 == 4: #每五次迭代            \n",
    "            end_time = time.time() #记录时间\n",
    "            \n",
    "            #展示模型训练状态\n",
    "            print(' ')\n",
    "            print('>' * 80)    \n",
    "            print('Epoch : {} - {}'.format(epoch - 3, epoch + 1))\n",
    "            print('Training_time = {} s / epoch'.format(str( (end_time - start_time) / 5 )[:8]) )\n",
    "            print('Avg_loss_function = {}'.format(np.mean(train_loss[-5:])))\n",
    "            if not cfg.mix_up:\n",
    "                print('Precision = {} %'.format(precision))            \n",
    "            print('>' * 80)\n",
    "            print(' ')\n",
    "            \n",
    "            if not cfg.mix_up and epoch / cfg.epoch_num > 0.1 and correct >= best_correct: #预热10%迭代, 更好的模型，mix_up下没法比较\n",
    "                best_correct = correct #更新最优结果\n",
    "                torch.save({'epoch': epoch, 'state_dict': model.state_dict(), 'best_correct': best_correct,\n",
    "                            'train_loss': train_loss, 'alpha': optimizer.state_dict()['param_groups'][0]['lr']}, #记录迭代次数，状态字典，最好结果, 损失函数list, 学习率\n",
    "                            os.path.join(cfg.save_path, 'model_{}_state.pkl'.format(cfg.model_name))) #最好的结果(覆盖原来的)\n",
    "            \n",
    "            if cfg.mix_up:\n",
    "                torch.save({'epoch': epoch, 'state_dict': model.state_dict(),\n",
    "                            'train_loss': train_loss, 'alpha': optimizer.state_dict()['param_groups'][0]['lr']}, #记录迭代次数，状态字典，最好结果, 损失函数list, 学习率\n",
    "                            os.path.join(cfg.save_path, 'model_{}_state.pkl'.format(cfg.model_name)))\n",
    "                \n",
    "                #torch.save(model.state_dict(), os.path.join(cfg.save_path, 'model_{}_state.pkl'.format(cfg.model_name))) #最好的结果(覆盖原来的)\n",
    "                #保存中间最好的模型(以后可以再训练) 保存模型所有信息，读取时要载入框架\n",
    "                #torch.save(model, './model_{}.pkl'.format(cfg.model_name)) #保存模型信息，读取时直接读取 等价\n",
    "\n",
    "            start_time = time.time() #更新时间\n",
    "            \n",
    "        torch.cuda.empty_cache() #清理显存\n",
    "        \n",
    "    if not os.path.exists(os.path.join(cfg.save_path, 'model_{}_state.pkl'.format(cfg.model_name))): #mix_up下 或者没更好结果 下保存最后结果\n",
    "        torch.save({'epoch': epoch, 'state_dict': model.state_dict(), 'best_correct': best_correct, \n",
    "                    'train_loss': train_loss, 'alpha': optimizer.state_dict()['param_groups'][0]['lr']}, #记录迭代次数，状态字典，最好结果, 损失函数list, 学习率\n",
    "                    os.path.join(cfg.save_path, 'model_{}_state.pkl'.format(cfg.model_name))) #最好的结果(覆盖原来的)\n",
    " \n",
    "    total_end_time = time.time() #记录时间           \n",
    "    \n",
    "    print('Training time = {} s / epoch'.format( str( (total_end_time - total_start_time) / cfg.epoch_num )[:8] ) )\n",
    "    print(' ')\n",
    "    print('Finish train')\n",
    "    print('>' * 80)    \n",
    "    print(' ')\n",
    "    print(' ')\n",
    "    \n",
    "    return train_loss\n",
    "\n",
    "    \n",
    "#模型测试\n",
    "#模型测试\n",
    "def test(testloader, cfg):\n",
    "    \"\"\"\n",
    "    :param: testloader 测试数据loader\n",
    "    :param: cfg 配置文件\n",
    "    return: precision 准确率\n",
    "    \"\"\"\n",
    "    print('>' * 80)\n",
    "    print('Begin test')\n",
    "    print(' ')\n",
    "\n",
    "    #载入模型结构   \n",
    "    model = get_model(cfg.model_name, cfg.classes, attention = cfg.attention) #根据模型名载入模型\n",
    "    if cfg.distribution:\n",
    "        model = torch.nn.DataParallel(model, device_ids = list(cfg.distribution))  \n",
    "    model_info = torch.load(os.path.join(cfg.save_path, 'model_{}_state.pkl'.format(cfg.model_name))) #获取字典\n",
    "    plt.plot(model_info['train_loss'])\n",
    "    model.load_state_dict(model_info['state_dict']) #加载训练出的模型\n",
    "    \n",
    "    #model.load_state_dict(torch.load(os.path.join(cfg.save_path, 'model_{}_state.pkl'.format(cfg.model_name)))) #加载训练出的模型\n",
    "    #model = torch.load(r'./model_{}.pkl'.format(cfg.model_name)) 等价\n",
    "    \n",
    "    model.eval() #测试，不改变权重\n",
    "    \n",
    "    test_list = pd.read_json(r'./test_list.json', orient = 'index')\n",
    "\n",
    "    device = torch.device(cfg.device) #选择设备\n",
    "    try: #用gpu\n",
    "        model.cuda(device) #设备选择\n",
    "        gpu = True #是否有gpu\n",
    "        print('Gpu is used')\n",
    "    except:#不用gpu\n",
    "        gpu = False\n",
    "        print('Cpu is used')\n",
    "    \n",
    "    correct = 0 #正确数\n",
    "    total = 0 #图片总数\n",
    "    wronglist = pd.DataFrame(columns = ['index', 'type', 'path']) #分错序号\n",
    "    #wronglist = []\n",
    "    predict_list = []\n",
    "    with torch.no_grad(): #不进行反向传播, 减少内存\n",
    "        \n",
    "        start_time = time.time() #记录时间\n",
    "        \n",
    "        for idx, (imgs, classes) in enumerate(testloader): #遍历图片\n",
    "           #索引  图片   类别\n",
    "           if gpu:#用gpu\n",
    "               imgs, classes = imgs.cuda(), classes.cuda()   # 将数据移到GPU上\n",
    "           inputs, targets = Variable(imgs), Variable(classes) #变量化输入x,y\n",
    "           \n",
    "           outputs = model(inputs) #运行模型(获得结果)\n",
    "           \n",
    "           _, predicted = torch.max(outputs.data, dim = 1) #获得预测结果，结果为批次数据, 所以行最大(一行一个结果)\n",
    "           #predict_list.append(predicted)\n",
    "           correct += predicted.eq(targets.data).cpu().sum().item() #正确数,cpu上算\n",
    "                   \n",
    "           if predicted.eq(targets.data).cpu().sum().item() != 1: #如果判断错\n",
    "               #wronglist.append((idx, classes))\n",
    "                wronglist.loc[len(wronglist)] = test_list.loc[idx]\n",
    "                #print(outputs.data)\n",
    "                \n",
    "           total += targets.size(0) #图片数加总(size第一维为批大小), size为大小\n",
    "\n",
    "        end_time = time.time()\n",
    "     \n",
    "        precision = 100. * correct / total #准确率\n",
    "        \n",
    "        torch.cuda.empty_cache() #清理显存\n",
    "    \n",
    "    json_wrong = wronglist.to_json(orient = 'index')\n",
    "    with open(r'./wronglist.json', 'w') as jsonFile:\n",
    "         jsonFile.write(json_wrong)\n",
    "    \n",
    "    print('Infering time = {} s / pic'.format( str( (end_time - start_time) / total )[:8] ) )\n",
    "    print(' ')\n",
    "    print('Finish test')\n",
    "    print('>' * 80)    \n",
    "    print(' ')\n",
    "    print(' ')\n",
    "    \n",
    "    print('Test Precision = {} %'.format(precision))   \n",
    "    \n",
    "    #print(predict_list)\n",
    "    \n",
    "    return precision, wronglist\n",
    "\n",
    "\n",
    "\n",
    "def main(config_path):\n",
    "    \"\"\"\n",
    "    主函数, 完成数据载入和模型训练 + 测试\n",
    "    :param: config_path config路径\n",
    "    return: train_loss,        precision,       wronglist       \n",
    "            各epcoh下训练损失   测试准确性       错判断序号列表\n",
    "    \"\"\"\n",
    "    torch.backends.cudnn.benchmark = True \n",
    "    cfg = Config(config_path) #获取配置文件\n",
    "    #if cfg.distribution:\n",
    "        #torch.distributed.init_process_group(backend = 'nccl', init_method = ,world_size = cfg.distribution)\n",
    "    trainloader, testloader, data_ok = get_data(cfg) #获取数据并进行数据预处理和增强\n",
    "    if data_ok:\n",
    "        train_loss = train(trainloader, cfg) #模型训练\n",
    "        precision, wronglist = test(testloader, cfg) #模型测试\n",
    "    \n",
    "        return train_loss, precision, wronglist \n",
    "    \n",
    "    else:\n",
    "        return None, None, None\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":        \n",
    "    train_loss, precision, wronglist = main(r'./config_cnn_dae.yml')\n",
    "    while True:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>type</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>xinguan</td>\n",
       "      <td>./DAE_metric_data/xin guan/xinguan_YANXIUFANG_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>xinguan</td>\n",
       "      <td>./DAE_metric_data/xin guan/xinguan_1018_303-Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>321</td>\n",
       "      <td>xinguan</td>\n",
       "      <td>./DAE_metric_data/xin guan/xinguan_CAOWENQIAO_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>434</td>\n",
       "      <td>xinguan</td>\n",
       "      <td>./DAE_metric_data/xin guan/xinguan_ZHANGDEJUN_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>493</td>\n",
       "      <td>xinguan</td>\n",
       "      <td>./DAE_metric_data/xin guan/xinguan_1016_302-Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>742</td>\n",
       "      <td>xinguan</td>\n",
       "      <td>./DAE_metric_data/xin guan/xinguan_1022_301-Ch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  index     type                                               path\n",
       "0     3  xinguan  ./DAE_metric_data/xin guan/xinguan_YANXIUFANG_...\n",
       "1    62  xinguan  ./DAE_metric_data/xin guan/xinguan_1018_303-Ch...\n",
       "2   321  xinguan  ./DAE_metric_data/xin guan/xinguan_CAOWENQIAO_...\n",
       "3   434  xinguan  ./DAE_metric_data/xin guan/xinguan_ZHANGDEJUN_...\n",
       "4   493  xinguan  ./DAE_metric_data/xin guan/xinguan_1016_302-Ch...\n",
       "5   742  xinguan  ./DAE_metric_data/xin guan/xinguan_1022_301-Ch..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wronglist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>type</th>\n",
       "      <th>path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>xinguan</td>\n",
       "      <td>./DAE_metric_data/xin guan/xinguan_YANXIUFANG_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>62</td>\n",
       "      <td>xinguan</td>\n",
       "      <td>./DAE_metric_data/xin guan/xinguan_1018_303-Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>130</td>\n",
       "      <td>xinguan</td>\n",
       "      <td>./DAE_metric_data/xin guan/xinguan_PENGFENG_ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>321</td>\n",
       "      <td>xinguan</td>\n",
       "      <td>./DAE_metric_data/xin guan/xinguan_CAOWENQIAO_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>434</td>\n",
       "      <td>xinguan</td>\n",
       "      <td>./DAE_metric_data/xin guan/xinguan_ZHANGDEJUN_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>493</td>\n",
       "      <td>xinguan</td>\n",
       "      <td>./DAE_metric_data/xin guan/xinguan_1016_302-Ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>525</td>\n",
       "      <td>xinguan</td>\n",
       "      <td>./DAE_metric_data/xin guan/xinguan_1004_2-ZS C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>742</td>\n",
       "      <td>xinguan</td>\n",
       "      <td>./DAE_metric_data/xin guan/xinguan_1022_301-Ch...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  index     type                                               path\n",
       "0     3  xinguan  ./DAE_metric_data/xin guan/xinguan_YANXIUFANG_...\n",
       "1    62  xinguan  ./DAE_metric_data/xin guan/xinguan_1018_303-Ch...\n",
       "2   130  xinguan  ./DAE_metric_data/xin guan/xinguan_PENGFENG_ba...\n",
       "3   321  xinguan  ./DAE_metric_data/xin guan/xinguan_CAOWENQIAO_...\n",
       "4   434  xinguan  ./DAE_metric_data/xin guan/xinguan_ZHANGDEJUN_...\n",
       "5   493  xinguan  ./DAE_metric_data/xin guan/xinguan_1016_302-Ch...\n",
       "6   525  xinguan  ./DAE_metric_data/xin guan/xinguan_1004_2-ZS C...\n",
       "7   742  xinguan  ./DAE_metric_data/xin guan/xinguan_1022_301-Ch..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wronglist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myTorch",
   "language": "python",
   "name": "mytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
