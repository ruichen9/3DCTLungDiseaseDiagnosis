{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-55219cd38a3b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m \u001b[0;31m#ç±»\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0malexnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mresnet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvgg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0msqueezenet\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0minception\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/models/alexnet.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_zoo\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmodel_zoo\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0m__all__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'AlexNet'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'alexnet'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/model_zoo.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0murlparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mrequests\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m     \u001b[0mrequests_available\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    110\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__copyright__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m__cake__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpackages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mRequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mResponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mPreparedRequest\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcerts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m# to_native_string is unused here, but imported here for backwards compatibility\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_internal_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mto_native_string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparse_http_list\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_parse_list_header\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m from .compat import (\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/_internal_utils.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \"\"\"\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mis_py2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuiltin_str\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/requests/compat.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0murlparse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murlunparse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murljoin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murlsplit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murlencode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquote\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munquote\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquote_plus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munquote_plus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murldefrag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mparse_http_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetproxies\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxy_bypass\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproxy_bypass_environment\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgetproxies_environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mhttp\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcookiejar\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcookielib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mhttp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcookies\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMorsel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mio\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/http/cookiejar.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    203\u001b[0m     r\"(\\d\\d\\d\\d) (\\d\\d):(\\d\\d):(\\d\\d) GMT$\", re.ASCII)\n\u001b[1;32m    204\u001b[0m WEEKDAY_RE = re.compile(\n\u001b[0;32m--> 205\u001b[0;31m     r\"^(?:Sun|Mon|Tue|Wed|Thu|Fri|Sat)[a-z]*,?\\s*\", re.I | re.ASCII)\n\u001b[0m\u001b[1;32m    206\u001b[0m LOOSE_HTTP_DATE_RE = re.compile(\n\u001b[1;32m    207\u001b[0m     r\"\"\"^\n",
      "\u001b[0;32m/usr/lib/python3.6/re.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    231\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m     \u001b[0;34m\"Compile a regular expression pattern, returning a pattern object.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mpurge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/re.py\u001b[0m in \u001b[0;36m_compile\u001b[0;34m(pattern, flags)\u001b[0m\n\u001b[1;32m    299\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misstring\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"first argument must be string or compiled pattern\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 301\u001b[0;31m     \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msre_compile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    302\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mDEBUG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    303\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_cache\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0m_MAXCACHE\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/sre_compile.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(p, flags)\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0mpattern\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m     \u001b[0mcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_code\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m     \u001b[0;31m# print(code)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/sre_compile.py\u001b[0m in \u001b[0;36m_code\u001b[0;34m(p, flags)\u001b[0m\n\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    550\u001b[0m     \u001b[0;31m# compile the pattern\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 551\u001b[0;31m     \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    552\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m     \u001b[0mcode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSUCCESS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/sre_compile.py\u001b[0m in \u001b[0;36m_compile\u001b[0;34m(code, pattern, flags)\u001b[0m\n\u001b[1;32m    124\u001b[0m                 \u001b[0memit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mav\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m                 \u001b[0memit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mav\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m                 \u001b[0m_compile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mav\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m                 \u001b[0memit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSUCCESS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m                 \u001b[0mcode\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mskip\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_len\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcode\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mskip\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/sre_compile.py\u001b[0m in \u001b[0;36m_compile\u001b[0;34m(code, pattern, flags)\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0mSUCCESS_CODES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_SUCCESS_CODES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mASSERT_CODES\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_ASSERT_CODES\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     if (flags & SRE_FLAG_IGNORECASE and\n\u001b[0m\u001b[1;32m     73\u001b[0m             \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mflags\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mSRE_FLAG_LOCALE\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m             \u001b[0mflags\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mSRE_FLAG_UNICODE\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/enum.py\u001b[0m in \u001b[0;36m__and__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mNotImplemented\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_\u001b[0m \u001b[0;34m&\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__xor__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/enum.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(cls, value, names, module, qualname, type, start)\u001b[0m\n\u001b[1;32m    291\u001b[0m         \"\"\"\n\u001b[1;32m    292\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mnames\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# simple value lookup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 293\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    294\u001b[0m         \u001b[0;31m# otherwise, functional API: we're creating a new Enum type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqualname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mqualname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/enum.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, value)\u001b[0m\n\u001b[1;32m    525\u001b[0m         \u001b[0;31m# see if it's in the reverse mapping (for hashable values)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    526\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 527\u001b[0;31m             \u001b[0;32mif\u001b[0m \u001b[0mvalue\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value2member_map_\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    528\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value2member_map_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    529\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Tue Jun 16 18:11:40 2020\n",
    "\n",
    "@author: 12057\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "import sys\n",
    "sys.path.append(r'/home/sufedc_nvidia_newgyh/apex')\n",
    "from apex import amp\n",
    "\n",
    "import torch\n",
    "\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn #ç±»\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import skimage.io as io\n",
    "import cv2\n",
    "import PIL\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from config import Config #è·åéç½®\n",
    "\n",
    "\n",
    "class Denoising_AutoEncoder(nn.Module):\n",
    "    \"\"\"\n",
    "    autoencoderç¥ç»ç½ç»ç»ææ­å»º\n",
    "    \"\"\"\n",
    "    cfg_conv = [[3, 64, 3, 1, 1], [64, 64, 3, 1, 1], 'M', [64, 128, 3, 1, 1], [128, 128, 3, 1, 1], 'M',\n",
    "                 [128, 256, 3, 1, 1], [256, 256, 3, 1, 1], [256, 256, 3, 1, 1], [256, 256, 3, 1, 1], 'M', \n",
    "                 [256, 512, 3, 1, 1], [512, 512, 3, 1, 1], [512, 512, 3, 1, 1], [512, 512, 3, 1, 1], 'M', \n",
    "                 [512, 512, 3, 1, 1], [512, 512, 3, 1, 1], [512, 512, 3, 1, 1], [512, 512, 3, 1, 1], 'M']\n",
    "    #encodeç½ç»æ¶æå¾  conv:[inner_channels, outer_channels, filter, stride, padding]\n",
    "                      #æå¤§æ± åå±:M  2*2 æ­¥é¿2\n",
    "\n",
    "    cfg_tranconv = ['M', [512, 512, 3, 1, 1], [512, 512, 3, 1, 1], [512, 512, 3, 1, 1], [512, 512, 3, 1, 1],\n",
    "                    'M', [512, 512, 3, 1, 1], [512, 512, 3, 1, 1], [512, 512, 3, 1, 1], [512, 256, 3, 1, 1],  \n",
    "                    'M', [256, 256, 3, 1, 1], [256, 256, 3, 1, 1], [256, 256, 3, 1, 1],  [256, 128, 3, 1, 1],\n",
    "                    'M', [128, 128, 3, 1, 1], [128, 64, 3, 1, 1], 'M', [64, 64, 3, 1, 1], [64, 3, 3, 1, 1]]     #decodeç½ç»æ¶æå¾  tran_conv:[inner_channels, outer_channels, filter, stride, padding]\n",
    "                     #æå¤§éæ± åå±:M  2*2 æ­¥é¿2\n",
    "\n",
    "    pool_kernel_size = 2 #æ± åå±æ ¸å¤§å°\n",
    "    pool_stride = 2 #æ± åå±æ­¥é¿\n",
    "\n",
    "    pool_index_list = [] #æ± ååå§æå¨ä½ç½®list\n",
    "    \n",
    "    def __init__(self, feature_len, img_size):\n",
    "        \"\"\"\n",
    "        åå§åå½æ°\n",
    "        :param: feature_len encodeé¿åº¦\n",
    "        :param: img_size å¾çå°ºå¯¸           \n",
    "        \"\"\"\n",
    "        \n",
    "        super(Denoising_AutoEncoder, self).__init__() #ç­ä»·ä¸nn.Module.__init__()   è¿ç¨nn.Moduleåå§å\n",
    "        \n",
    "        self.img_size = img_size #å¾çå¤§å°\n",
    "        self.feature_len = feature_len #encodeé¿åº¦\n",
    "        self.in_channels = 3 #è®°å½è¾å¥å±æ°ï¼ç¨äºç½ç»è¾å¥\n",
    "        self.en_net = self.encode_conv() #encodeç½ç»\n",
    "        self.en_fc = nn.Linear(in_features = self.in_channels * self.img_size[0] * self.img_size[1], out_features = self.feature_len, bias = True) #encodeæåçå¨è¿æ¥å±       \n",
    "        self.de_fc = nn.Linear(in_features = self.feature_len, out_features = self.in_channels * self.img_size[0] * self.img_size[1], bias = True) #decodeæåçå¨è¿æ¥å±     \n",
    "        self.de_net = self.decode_conv() #decodeç½ç»     \n",
    "\n",
    "    def corrupt_x(self, x, cor_rate = 0.01):\n",
    "        \"\"\"\n",
    "        å¯¹äºxè¿è¡éæºcorrupt\n",
    "        :param: x è¾å¥åéx\n",
    "        :param: cor_rate éæºcorruptæ¦ç\n",
    "        return corrupted_x corruptåçåéx\n",
    "        \"\"\"\n",
    "        judge_matrix = np.random.randn(*list(x.shape)) > cor_rate\n",
    "        judge_matrix = judge_matrix.astype('float32')\n",
    "        judge_matrix = torch.FloatTensor(judge_matrix)\n",
    "        try: #ç¨gpu\n",
    "            judge_matrix = judge_matrix.cuda(x.device)\n",
    "        except: #ç¨cpu\n",
    "            pass\n",
    "        corrupted_x = x * judge_matrix\n",
    "        \n",
    "        return corrupted_x\n",
    "    \n",
    "    def encode_conv(self):\n",
    "        \"\"\"\n",
    "        å»ºç«encodeé¨åç½ç», ä¸ç¨ReLUç¨çç¹å¾, ä¸ç¨æ± åå±\n",
    "        return  encode_feature_net  encodeé¨å\n",
    "        \"\"\"\n",
    "        encode_feature_net = []\n",
    "        for layer_type in self.cfg_conv:\n",
    "            if layer_type == 'M':\n",
    "                layer = [nn.MaxPool2d(kernel_size = self.pool_kernel_size, stride = self.pool_stride, return_indices = True)]#æå¤§æ± åå±\n",
    "                        #å¯¹åºåå§æå¨ä½ç½® \n",
    "                self.img_size[0] = int((self.img_size[0] - self.pool_kernel_size) / self.pool_stride + 1) #è®¡ç®å¾çå¤§å°\n",
    "                self.img_size[1] = int((self.img_size[1] - self.pool_kernel_size) / self.pool_stride + 1)#è®¡ç®å¾çå¤§å°\n",
    "            else: #å·ç§¯å±\n",
    "                in_channels, out_channels, kernel_size, stride, padding = layer_type\n",
    "                self.img_size[0] = int((self.img_size[0] - kernel_size + 2 * padding) / stride + 1) #è®¡ç®å¾çå¤§å°\n",
    "                self.img_size[1] = int((self.img_size[1] - kernel_size + 2 * padding) / stride + 1)#è®¡ç®å¾çå¤§å°\n",
    "                layer = [nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding), #å·ç§¯å±\n",
    "                                  #è¾å¥ééæ°     è¾åºç¹å¾æ°    å·ç§¯æ ¸å¤§å°    æ­¥é¿    å¡«å\n",
    "                         nn.BatchNorm2d(num_features = out_channels), #BNå±\n",
    "                                             #ç¹å¾æ°\n",
    "                         nn.Tanh()]  #Tanhå± \n",
    "                         #inplace=Trueæ¹åè¾å¥çæ°æ®, èçåå­\n",
    "                self.in_channels = out_channels\n",
    "                \n",
    "            encode_feature_net += layer\n",
    "                  \n",
    "        return nn.Sequential(*encode_feature_net)\n",
    "    \n",
    "    \n",
    "    def decode_conv(self):\n",
    "        \"\"\"\n",
    "        å»ºç«decodeé¨åç½ç», ä¸ç¨ReLUç¨çç¹å¾, ä¸ç¨éæ± åå±\n",
    "        return  decode_pic_net  encodeé¨å\n",
    "        \"\"\"\n",
    "        decode_pic_net = []\n",
    "        for layer_type in self.cfg_tranconv:\n",
    "            if layer_type == 'M':\n",
    "                layer = [nn.MaxUnpool2d(kernel_size = self.pool_kernel_size, stride = self.pool_stride)]#æå¤§éæ± åå±\n",
    "            else: #å·ç§¯å±\n",
    "                in_channels, out_channels, kernel_size, stride, padding = layer_type\n",
    "                layer = [nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding), #å·ç§¯å±\n",
    "                                  #è¾å¥ééæ°     è¾åºç¹å¾æ°    å·ç§¯æ ¸å¤§å°    æ­¥é¿    å¡«å\n",
    "                         nn.BatchNorm2d(num_features = out_channels), #BNå±\n",
    "                                             #ç¹å¾æ°\n",
    "                         nn.Tanh()]  #Tanhå± \n",
    "                         #inplace=Trueæ¹åè¾å¥çæ°æ®, èçåå­\n",
    "                #self.in_channels = out_channels\n",
    "                \n",
    "            decode_pic_net += layer\n",
    "        decode_pic_net[-1] = nn.Sigmoid() #æåä¸å±æ¹æSigmoid è®©è¾å¥ä¸º0-1ä¹é´\n",
    "            \n",
    "        return nn.Sequential(*decode_pic_net)\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        ååä¼ æ­\n",
    "        :param: x å¾çåé\n",
    "        return code: å¾çencodeç¼ç  \n",
    "               decode: encodeç¼ç  decodeç»æ\n",
    "        \"\"\"\n",
    "        \n",
    "        code = self.corrupt_x(x) #corrupt_x\n",
    "        for net in self.en_net: #encodeé¨å\n",
    "            if isinstance(net, nn.MaxPool2d):\n",
    "                code, pool_index = net(code)  #è·åæ± åä½ç½®\n",
    "                self.pool_index_list.append(pool_index)\n",
    "            else:\n",
    "                code = net(code)\n",
    "                \n",
    "        code = code.view(code.size(0), -1)\n",
    "        code = self.en_fc(code)\n",
    "        \n",
    "        decode = self.de_fc(code)\n",
    "        decode = decode.view(decode.size(0), self.in_channels, self.img_size[0], self.img_size[1])\n",
    "        \n",
    "        for net in self.de_net: #decodeé¨å\n",
    "            if isinstance(net, nn.MaxUnpool2d):\n",
    "                decode = net(decode, self.pool_index_list.pop())\n",
    "            else:\n",
    "                decode = net(decode)\n",
    "        \n",
    "        return code, decode\n",
    "\n",
    "    def encode_data(self, x):\n",
    "        code = x \n",
    "        for net in self.en_net: #encodeé¨å\n",
    "            if isinstance(net, nn.MaxPool2d):\n",
    "                code, pool_index = net(code)  #è·åæ± åä½ç½®\n",
    "                self.pool_index_list.append(pool_index)\n",
    "            else:\n",
    "                code = net(code)\n",
    "                \n",
    "        code = code.view(code.size(0), -1)\n",
    "        code = self.en_fc(code)\n",
    "        \n",
    "        return code\n",
    "    \n",
    "def get_data(cfg):\n",
    "    \"\"\"\n",
    "    è·åé¢å¤çåæ°æ®å¢å¼ºåçæ°æ®é\n",
    "    :param: cfg éç½®æä»¶\n",
    "    return trainloader, testloader, data_ok\n",
    "           è®­ç»loader   æµè¯loader  æ°æ®æ¯å¦è·å¾\n",
    "    \"\"\"\n",
    "    print('>' * 80)\n",
    "    print('Date getting begin')\n",
    "    print('')\n",
    "    \n",
    "    try: \n",
    "        #è®­ç»éæ°æ®è·å\n",
    "        \n",
    "        #è®­ç»éæ°æ®é¢å¤ç\n",
    "        transform_train = transforms.Compose([\n",
    "            transforms.Resize(size = cfg.resize_size, interpolation = PIL.Image.BILINEAR), #è°æ´å¤§å°ä¸è´ï¼ææå¾çå¤§å°éè¦ä¸è´\n",
    "            transforms.ToTensor(),\n",
    "            #transforms.Normalize(mean = (0.4914, 0.4822, 0.4465), std = (0.2023, 0.1994, 0.2010)),\n",
    "        ])\n",
    "        trainset = torchvision.datasets.ImageFolder(os.path.join(cfg.data_info, 'train'), transform = transform_train)\n",
    "        \n",
    "        #testset = torchvision.datasets.ImageFolder(os.path.join(cfg.data_info, 'test',), transform = transform_train)\n",
    "                      \n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size = cfg.batch_size, shuffle = True, num_workers = 0)\n",
    "\n",
    "        testloader = torch.utils.data.DataLoader(trainset, batch_size = 1, shuffle = False, num_workers = 0)\n",
    "\n",
    "        print('Succeeded to get_data')\n",
    "        print('>' * 80)\n",
    "        print(' ')\n",
    "        print(' ')\n",
    "        \n",
    "        return trainloader, testloader, True \n",
    "    \n",
    "    except: #é²ç\n",
    "        \n",
    "        print('Failed to get_data, stop training')\n",
    "        print('>' * 80)\n",
    "        print(' ')\n",
    "        print(' ')\n",
    "        \n",
    "        return None, None, False\n",
    "    \n",
    "\"\"\"\n",
    "éç¨æ¨¡ååå§å\n",
    "\"\"\"\n",
    "def initialize_weights(model):\n",
    "    \"\"\"\n",
    "    æ¨¡ååå§å\n",
    "    :param:model è¾å¥æ¨¡å å¯ä»¥ç¨model.apply(initialize_weights)è°ç¨\n",
    "    \"\"\"\n",
    "    for module in model.modules(): #æ¨¡åä¸­çæææ¨¡å¼ï¼åå«æ»ï¼åºåï¼å±\n",
    "        \n",
    "        if isinstance(module, nn.Conv2d): #å·ç§¯å±\n",
    "            n_conv = module.kernel_size[0] * module.kernel_size[1] * module.out_channels #å·ç§¯æéåç´ ä¸ªæ°\n",
    "            module.weight.data.normal_(0, math.sqrt(2. / n_conv)) #å·ç§¯æ ¸åå§å æ­£æéæºæ°, éå¶æ åå·®\n",
    "            if module.bias is not None: #æåç§»é¡¹\n",
    "                module.bias.data.zero_() #åç§»é¡¹åå§å = 0\n",
    "                \n",
    "        elif isinstance(module, nn.BatchNorm2d): #BNå±\n",
    "            module.weight.data.fill_(1) #å½ä¸åæé == æ åå·®, åå§å = 1\n",
    "            module.bias.data.zero_() #å½ä¸ååç§»é¡¹ == åå¼, åå§å = 0\n",
    "            \n",
    "        elif isinstance(module, nn.Linear): #å¨è¿æ¥å±\n",
    "            n_fc = module.in_features * module.out_features #å¨è¿æ¥å±æéä¸ªæ°\n",
    "            module.weight.data.normal_(0, math.sqrt(2. / n_fc)) #å¨è¿æ¥æéæ­£æåå§å\n",
    "            module.bias.data.zero_()#åç§»é¡¹åå§å = 0\n",
    "            \n",
    "        elif isinstance(module, nn.ConvTranspose2d): #åå·ç§¯å±\n",
    "            n_conv = module.kernel_size[0] * module.kernel_size[1] * module.out_channels #å·ç§¯æéåç´ ä¸ªæ°\n",
    "            module.weight.data.normal_(0, math.sqrt(2. / n_conv)) #å·ç§¯æ ¸åå§å æ­£æéæºæ°, éå¶æ åå·®\n",
    "            if module.bias is not None: #æåç§»é¡¹\n",
    "                module.bias.data.zero_() #åç§»é¡¹åå§å = 0\n",
    "                \n",
    "#æ¨¡åè®­ç»\n",
    "def train(trainloader, cfg):\n",
    "    \"\"\"\n",
    "    :param: trainloader è®­ç»æ°æ®loader\n",
    "    :param: cfg éç½®æä»¶\n",
    "    return train_loss åepochè®­ç»æå¤±å½æ°list\n",
    "    \"\"\"\n",
    "    print('>' * 80)    \n",
    "    print('Begin train')\n",
    "    print(' ')\n",
    "\n",
    "    #æ¨¡ååºæ¬éç½®\n",
    "    print('Model use {}'.format(cfg.model_name))\n",
    "    print(' ')\n",
    "    \n",
    "    model = Denoising_AutoEncoder(cfg.classes_num, list(cfg.resize_size)) #è½½å¥æ¨¡å\n",
    "\n",
    "    begin_epoch = 0 #åå§epoch\n",
    "    if cfg.pretrain: #å¦ææé¢è®­ç»\n",
    "        model_info = torch.load(os.path.join(cfg.pretrain, 'model_{}_state.pkl'.format(cfg.model_name)))\n",
    "        model.load_state_dict(model_info['state_dict']) #å è½½è®­ç»åºçæ¨¡å\n",
    "        begin_epoch = model_info['epoch'] + 1\n",
    "\n",
    "    model.train() #åæ¢å°è®­ç»æ¨¡å¼\n",
    "          \n",
    "    device = torch.device(cfg.device) #éæ©è®¾å¤\n",
    "    try: #ægpu\n",
    "        model.cuda(device) #è®¾å¤éæ©\n",
    "        gpu = True #æ¯å¦ægpu\n",
    "        print('Gpu is used')\n",
    "    except:#ä¸ç¨gpu\n",
    "        gpu = False\n",
    "        print('Cpu is used')\n",
    "    \n",
    "    criterion = torch.nn.MSELoss() #æå¤±å½æ°æ¹æ³ï¼MSE\n",
    "    alpha = cfg.alpha if not cfg.pretrain else model_info['alpha'] #åå§å­¦ä¹ çï¼æé¢å¤çä»¥é¢å¤çä¸ºå\n",
    "    optimizer = torch.optim.SGD(model.parameters(), momentum = cfg.momentum, lr = alpha, weight_decay = cfg.weight_decay) #è¿­ä»£æ¹æ³SGD\n",
    "                                                           #å¨é              åå§å­¦ä¹ ç            æéè¡°åè¶å¿\n",
    "    #optimizer = torch.optim.Adam(model.parameters(), lr = 0.001, betas = (0.9, 0.999), eps = 1e-8, weight_decay = cfg.weight_decay) #è¿­ä»£æ¹æ³Adam\n",
    "                                                       #å­¦ä¹ ç      æ¢¯åº¦åæ¢¯åº¦å¹³æ¹ç³»æ°   åæ¯é²é¶ä¿®æ­£           æéè¡°åç³»æ°\n",
    "                                                       \n",
    "    #scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = 10) #å­¦ä¹ çè¡°å(ä½å¼¦éç«)\n",
    "                                                        #0, T_maxä¸éï¼T_maxå°2 * T_maxä¸å\n",
    "    #scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer,lr_lambda = lambda step:np.sin(step) / step) #èªå·±è®¾å®,å½æ°è¾å¥ä¸ºæ­¥æ°\n",
    "                                                                    #èªå·±è®¾å®å½æ°\n",
    "    #scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones = [20, 80], gamma = 0.9) #åæ®µå¼è¡°å\n",
    "                                                                #è®¾å®ååç¹ï¼éå°è¯¥ç¹åå  è¡°åç³»æ°\n",
    "    #scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.99) #ææ°è¡°åï¼æ¯ä¸ªepoch\n",
    "                                                                   #è¡°åç³»æ°\n",
    "    #scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode = 'min', factor = 0.1, patience = 10, verbose = False, threshold = 0.0001, threshold_mode = 'rel', cooldown = 0, min_lr = 0, eps = 1e-08) #èªéåº\n",
    "                                                                     #æ£æµlossåå°     è¡°åç³»æ°       å®¹å¿æ¬¡æ°        æ¯å¦print         ååéå¼èå´        relæ¯ä¾ abså¼           å·å´æ¶é´      æå°lr     ææè¾å·®ä¸å                                  \n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = cfg.lr_step, gamma = cfg.lr_decay) #å­¦ä¹ ççº¿æ§è¡°å\n",
    "                                                                 #è¡°åæ­¥é¿         è¡°åç³»æ° lr *= lr_decay\n",
    "    if not cfg.pretrain: #å¦ææ²¡é¢è®­ç»\n",
    "        model.apply(initialize_weights) #æ¨¡ååå§åï¼åç½®åå§åï¼åååå¸\n",
    "    \n",
    "    if gpu:\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level = \"O1\", verbosity = 0) #æ··åç²¾åº¦æ¨¡å\n",
    "                                              #Oo fp32, O1æ··å, O2å ä¹fp16, O3 fp16  \n",
    "    if cfg.distribution:\n",
    "        model = torch.nn.DataParallel(model, device_ids = list(range(cfg.distribution)))\n",
    "        \n",
    "    if cfg.pretrain: #å¦æé¢è®­ç»\n",
    "        train_loss = model_info['train_loss']\n",
    "    else:\n",
    "        train_loss = []\n",
    "    \n",
    "    total_start_time = time.time() #è®°å½æ¶é´\n",
    "    start_time = time.time() #è®°å½æ¶é´\n",
    "    \n",
    "    for epoch in tqdm(range(begin_epoch, cfg.epoch_num)): #è¿­ä»£å¨å¾\n",
    "    #for epoch in range(1, cfg.epoch_num + 1): #è¿­ä»£å¨å¾  \n",
    "        \n",
    "        train_loss_i = 0 #ç¬¬iæ¬¡epochæå¤±\n",
    "        for batch_idx, (imgs, _) in enumerate(trainloader): #è¿­ä»£æ¹æ¬¡\n",
    "            #æ¹æ°       å¾ç\n",
    "            \n",
    "            #one-hot label åï¼(äº¤åçµéé¢èªå¨æ)\n",
    "            #classes = torch.zeros(cfg.batch_size, len(cfg.classes)).scatter_(1, classes.view(len(classes),1), 1)\n",
    "                                                                     #ç¨çå ç»´åº¦       å¼                  å¯¹åºæ ç­¾å¼           \n",
    "            if gpu: #ç¨gpu\n",
    "                imgs = imgs.cuda(device) #å°æ°æ®ç§»å°GPUä¸\n",
    "                inputs= Variable(imgs)  #åéåè¾å¥x,y\n",
    "         \n",
    "            optimizer.zero_grad()   # åå°optimizeræ¢¯åº¦åç½®ä¸º0\n",
    "            \n",
    "            encode, decode = model(inputs) #ååä¼ æ­\n",
    "            #outputs = model.forward(inputs) #ç­ä»·ææ\n",
    "            \n",
    "            loss = criterion(inputs, decode) #æå¤±å½æ°\n",
    "\n",
    "            if gpu:\n",
    "                with amp.scale_loss(loss, optimizer) as scaled_loss:#éç¨æ··åç²¾åº¦æ¨¡å         \n",
    "                    scaled_loss.backward() \n",
    "            else:\n",
    "                loss.backward()  #ååä¼ æ­ï¼è®¡ç®æ¢¯åº¦\n",
    "            \n",
    "            optimizer.step() #æ´æ°åæ°\n",
    "        \n",
    "            train_loss_i += loss.data.item()#è®°å½æ¯æ¬¡è®­ç»Loss, å¿é¡»loss.data[0]\n",
    "            \n",
    "        \n",
    "        scheduler.step() #å­¦ä¹ çè®°å½step      \n",
    "        train_loss.append(train_loss_i) #è®°å½æ¯è½®çæå¤±å½æ°å¼\n",
    "        \n",
    "        if  epoch % 5 == 4: #æ¯åæ¬¡è¿­ä»£            \n",
    "            end_time = time.time() #è®°å½æ¶é´\n",
    "            \n",
    "            #å±ç¤ºæ¨¡åè®­ç»ç¶æ\n",
    "            print(' ')\n",
    "            print('>' * 80)    \n",
    "            print('Epoch : {} - {}'.format(epoch - 3, epoch + 1))\n",
    "            print('Training_time = {} s / epoch'.format(str( (end_time - start_time) / 5 )[:8]) )\n",
    "            print('Avg_loss_function = {}'.format(np.mean(train_loss[-5:])))\n",
    "            print('>' * 80)\n",
    "            print(' ')\n",
    "            \n",
    "            if not cfg.mix_up and epoch / cfg.epoch_num > 0.1: #é¢ç­10%è¿­ä»£\n",
    "                torch.save({'epoch': epoch, 'state_dict': model.state_dict(), \n",
    "                            'train_loss': train_loss, 'alpha': optimizer.state_dict()['param_groups'][0]['lr']}, #è®°å½è¿­ä»£æ¬¡æ°ï¼ç¶æå­å¸ï¼æå¥½ç»æ, æå¤±å½æ°list, å­¦ä¹ ç\n",
    "                            os.path.join(cfg.save_path, 'model_{}_state.pkl'.format(cfg.model_name))) #æå¥½çç»æ(è¦çåæ¥ç)\n",
    "                \n",
    "                #torch.save(model.state_dict(), os.path.join(cfg.save_path, 'model_{}_state.pkl'.format(cfg.model_name))) #æå¥½çç»æ(è¦çåæ¥ç)\n",
    "                #ä¿å­ä¸­é´æå¥½çæ¨¡å(ä»¥åå¯ä»¥åè®­ç») ä¿å­æ¨¡åææä¿¡æ¯ï¼è¯»åæ¶è¦è½½å¥æ¡æ¶\n",
    "                #torch.save(model, './model_{}.pkl'.format(cfg.model_name)) #ä¿å­æ¨¡åä¿¡æ¯ï¼è¯»åæ¶ç´æ¥è¯»å ç­ä»·\n",
    "\n",
    "            start_time = time.time() #æ´æ°æ¶é´\n",
    "            \n",
    "        torch.cuda.empty_cache() #æ¸çæ¾å­\n",
    "         \n",
    "    total_end_time = time.time() #è®°å½æ¶é´           \n",
    "    \n",
    "    print('Training time = {} s / epoch'.format( str( (total_end_time - total_start_time) / cfg.epoch_num )[:8] ) )\n",
    "    print(' ')\n",
    "    print('Finish train')\n",
    "    print('>' * 80)    \n",
    "    print(' ')\n",
    "    print(' ')\n",
    "    \n",
    "    return train_loss\n",
    "\n",
    "    \n",
    "#æ¨¡åæµè¯\n",
    "def test(testloader, cfg):\n",
    "    \"\"\"\n",
    "    æµè¯Auto_encoderææ\n",
    "    :param: testloader æµè¯æ°æ®loader\n",
    "    :param: cfg éç½®æä»¶\n",
    "    return: precision åç¡®ç\n",
    "    \"\"\"\n",
    "    print('>' * 80)\n",
    "    print('Begin test')\n",
    "    print(' ')\n",
    "    \n",
    "    dic_class = {0: 'xinguan', 1: 'noxinguan'}\n",
    "    if not os.path.exists(os.path.join(cfg.save_path, 'dae_result')):\n",
    "        os.mkdir(os.path.join(cfg.save_path, 'dae_result'))\n",
    "        for key in dic_class:\n",
    "            os.mkdir(os.path.join(cfg.save_path, 'dae_result', dic_class[key]))\n",
    "        \n",
    "    #è½½å¥æ¨¡åç»æ   \n",
    "    model = Denoising_AutoEncoder(cfg.classes_num, list(cfg.resize_size)) #è½½å¥æ¨¡å\n",
    "    \n",
    "    model_info = torch.load(os.path.join(cfg.save_path, 'model_{}_state.pkl'.format(cfg.model_name))) #è·åå­å¸\n",
    "    model.load_state_dict(model_info['state_dict']) #å è½½è®­ç»åºçæ¨¡å\n",
    "    \n",
    "    #model.load_state_dict(torch.load(os.path.join(cfg.save_path, 'model_{}_state.pkl'.format(cfg.model_name)))) #å è½½è®­ç»åºçæ¨¡å\n",
    "    #model = torch.load(r'./model_{}.pkl'.format(cfg.model_name)) ç­ä»·\n",
    "    \n",
    "    model.eval() #æµè¯ï¼ä¸æ¹åæé\n",
    "\n",
    "    device = torch.device(cfg.device) #éæ©è®¾å¤\n",
    "    try: #ç¨gpu\n",
    "        model.cuda(device) #è®¾å¤éæ©\n",
    "        gpu = True #æ¯å¦ægpu\n",
    "        print('Gpu is used')\n",
    "    except:#ä¸ç¨gpu\n",
    "        gpu = False\n",
    "        print('Cpu is used')\n",
    "    \n",
    "    total = 0 #å¾çæ»æ°\n",
    "\n",
    "    with torch.no_grad(): #ä¸è¿è¡ååä¼ æ­, åå°åå­\n",
    "    \n",
    "        start_time = time.time() #è®°å½æ¶é´\n",
    "        \n",
    "        for idx, (imgs, classes) in enumerate(testloader): #éåå¾ç\n",
    "           #ç´¢å¼  å¾ç  \n",
    "           if gpu:#ç¨gpu\n",
    "               imgs= imgs.cuda(device)   # å°æ°æ®ç§»å°GPUä¸\n",
    "           inputs = Variable(imgs) #åéåè¾å¥x\n",
    "           \n",
    "           encode, decode = model(inputs) #è¿è¡æ¨¡å(è·å¾ç»æ)\n",
    "           \n",
    "           encode_pic = encode.cpu().numpy()[0, :]\n",
    "           classes = int(classes.cpu().numpy())\n",
    "           #print(classes)\n",
    "           encode_size = int(np.sqrt(len(encode_pic)))\n",
    "           encode_pic = np.reshape(encode_pic, (encode_size, encode_size))\n",
    "           np.save(os.path.join(cfg.save_path, 'dae_result', dic_class[classes], str(idx) + '.npy'), encode_pic)\n",
    "           #with open(os.path.join(cfg.save_path, 'dae_result', dic_class[classes], str(idx) + '.pkl'), 'wb') as pkl:\n",
    "                #pickle.dump(encode_pic, pkl)\n",
    "\n",
    "           #dec_pic = transforms.ToPILImage()(decode.cpu()[0, :, :, :])       \n",
    "           #dec_pic.save(os.path.join(cfg.save_path, 'ae_result', str(idx) + '.png')) #ç­ä»·æ¹æ³\n",
    "           \n",
    "           total += 1\n",
    "        \n",
    "        end_time = time.time()\n",
    "             \n",
    "        torch.cuda.empty_cache() #æ¸çæ¾å­\n",
    "    \n",
    "    print('Encoding time = {} s / pic'.format( str( (end_time - start_time) / total )[:8] ) )\n",
    "    print(' ')\n",
    "    print('Finish test')\n",
    "    print('>' * 80)    \n",
    "    print(' ')\n",
    "    print(' ')\n",
    "        \n",
    "    \n",
    "    \n",
    "def main(config_path = r'./config_ae.yml'):\n",
    "    \"\"\"\n",
    "    ä¸»å½æ°, å®ææ°æ®è½½å¥åæ¨¡åè®­ç» + æµè¯\n",
    "    :param: config_path configè·¯å¾\n",
    "    return: train_loss,        precision,       wronglist       \n",
    "            åepcohä¸è®­ç»æå¤±   æµè¯åç¡®æ§       éå¤æ­åºå·åè¡¨\n",
    "    \"\"\"\n",
    "    cfg = Config(config_path) #è·åéç½®æä»¶\n",
    "    trainloader, testloader, data_ok = get_data(cfg) #è·åæ°æ®å¹¶è¿è¡æ°æ®é¢å¤çåå¢å¼º\n",
    "    if data_ok:\n",
    "        train_loss = train(trainloader, cfg) #æ¨¡åè®­ç»\n",
    "        test(testloader, cfg) #æ¨¡åè®­ç»\n",
    "        return train_loss\n",
    "    \n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":        \n",
    "    train_loss = main(r'./config_dae.yml')\n",
    "    while True:\n",
    "        pass\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = (1,2,3)\n",
    "import torch\n",
    "torch.tensor(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
