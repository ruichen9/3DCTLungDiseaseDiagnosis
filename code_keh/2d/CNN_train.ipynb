{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Config loading begin\n",
      "\n",
      "Data: dae_data\n",
      "\n",
      "Succeed to read classes file\n",
      "Succeed to read config file\n",
      "Config loading is valid\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      " \n",
      " \n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Date getting begin\n",
      "\n",
      "Succeeded to get_data\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      " \n",
      " \n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Begin train\n",
      " \n",
      "Model use ResNet_50\n",
      " \n",
      "Gpu is used\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training time = 5.319383 s / epoch\n",
      " \n",
      "Finish train\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      " \n",
      " \n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "Begin test\n",
      " \n",
      "Gpu is used\n",
      "Infering time = 0.054338 s / pic\n",
      " \n",
      "Finish test\n",
      ">>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      " \n",
      " \n",
      "Test Precision = 90.86294416243655 %\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sat Mar 14 20:09:47 2020\n",
    "\n",
    "@author: 12057\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import sys\n",
    "sys.path.append(r'/home/sufedc_nvidia_newgyh/apex')\n",
    "from apex import amp\n",
    "\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "import PIL\n",
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from config import Config #获取配置\n",
    "from Pytorch_nets import * #自定义的神经网络\n",
    "from Data_Augment_New import * #自定义的数据增强方法 对PIL Image\n",
    "from CV_tricks import * #自定义的CV的tricks\n",
    "\n",
    "\"\"\"\n",
    "epoch: 全部图片迭代一次\n",
    "iteration: 一个batch迭代一次\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "#获取数据，并进行预处理和数据增强\n",
    "\n",
    "def get_data(cfg):\n",
    "    \"\"\"\n",
    "    获取预处理和数据增强后的数据集\n",
    "    :param: cfg 配置文件\n",
    "    return trainloader, testloader, data_ok\n",
    "           训练loader   测试loader  数据是否获得\n",
    "    \"\"\"\n",
    "    print('>' * 80)\n",
    "    print('Date getting begin')\n",
    "    print('')\n",
    "    \n",
    "    try:\n",
    "        #训练集预处理\n",
    "        transform_train = transforms.Compose(\n",
    "            [#自定义数据增强方法\n",
    "            #transforms.Lambda(lambda img: sidecrop(img)), #必须裁边的图像裁剪\n",
    "            transforms.Lambda(lambda img: addblack(img)) #图像加黑边\n",
    "            ] + \\\n",
    "            [#传统数据增强\n",
    "            #transforms.RandomCrop(size = cfg.cut_size, padding = 4), #随机裁剪 + 缩放\n",
    "            transforms.RandomHorizontalFlip(p = 0.5), #随机水平翻转\n",
    "            transforms.RandomResizedCrop(size = cfg.resize_size[0], scale = cfg.cut_scale, ratio = cfg.cut_ratio), #随机长宽比范围裁剪,再缩放\n",
    "                                                 #缩放后大小,整数    面积比例范围        长宽比比例范围\n",
    "            transforms.Resize(size = cfg.resize_size, interpolation = PIL.Image.BILINEAR), #调整大小一致，所有图片大小需要一致\n",
    "                                                              #插值方法\n",
    "            transforms.ToTensor(), #tensor化：固定操作  函数接受PIL Image或numpy.ndarray，将其先由HWC转置为CHW格式，再转为float后每个像素除以255.\n",
    "            transforms.Normalize(mean = (0.4914, 0.4822, 0.4465), std = (0.2023, 0.1994, 0.2010)) #标准化：固定操作\n",
    "            ])\n",
    "    \n",
    "        #测试集预处理\n",
    "        transform_test = transforms.Compose([\n",
    "            transforms.Resize(size = cfg.resize_size, interpolation = PIL.Image.BILINEAR), #调整大小一致，所有图片大小需要一致\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean = (0.4914, 0.4822, 0.4465), std = (0.2023, 0.1994, 0.2010)),\n",
    "        ])\n",
    "        \n",
    "        if cfg.data_info == 'CIFAR10':\n",
    "            #CIFAR10数据   \n",
    "            #训练集数据获取\n",
    "            trainset = torchvision.datasets.CIFAR10(root = r'./CIFAR10_data', train = True, download = True, transform = transform_train)\n",
    "                                                         #目标路径              是否训练     是否下载,已下载也没事      数据变换类型  \n",
    "            #测试集数据获取\n",
    "            testset = torchvision.datasets.CIFAR10(root = r'./CIFAR10_data', train = False, download = True, transform = transform_test)\n",
    "        \n",
    "        else:\n",
    "            #自定义数据   \n",
    "            #训练集数据获取\n",
    "            trainset = torchvision.datasets.ImageFolder(os.path.join(cfg.data_info, 'train'), transform = transform_train)\n",
    "                                                            #数据集所在文件夹，一个文件夹为一类        \n",
    "            #测试集数据获取\n",
    "            testset = torchvision.datasets.ImageFolder(os.path.join(cfg.data_info, 'test'), transform = transform_test)\n",
    "            \n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size = cfg.batch_size, shuffle = True, num_workers = 0)\n",
    "                                                  #数据集   批大小(自动化)               是否每次打乱(一般True)  多进程数\n",
    "        testloader = torch.utils.data.DataLoader(testset, batch_size = 1, shuffle = False, num_workers = 0)\n",
    "                                                         #测试集不需要batch和shuffle   \n",
    "            \n",
    "        print('Succeeded to get_data')\n",
    "        print('>' * 80)\n",
    "        print(' ')\n",
    "        print(' ')\n",
    "        \n",
    "        return trainloader, testloader, True \n",
    "    \n",
    "    except: #防爆\n",
    "        \n",
    "        print('Failed to get_data, stop training')\n",
    "        print('>' * 80)\n",
    "        print(' ')\n",
    "        print(' ')\n",
    "        \n",
    "        return None, None, False\n",
    "           \n",
    "\n",
    "#模型训练\n",
    "\n",
    "def train(trainloader, cfg):\n",
    "    \"\"\"\n",
    "    :param: trainloader 训练数据loader\n",
    "    :param: cfg 配置文件\n",
    "    return train_loss 各epoch训练损失函数list\n",
    "    \"\"\"\n",
    "    print('>' * 80)    \n",
    "    print('Begin train')\n",
    "    print(' ')\n",
    "\n",
    "    #模型基本配置\n",
    "    print('Model use {}'.format(cfg.model_name))\n",
    "    print(' ')\n",
    "    model = get_model(cfg.model_name, cfg.classes, attention = cfg.attention) #根据模型名载入模型\n",
    "    \n",
    "    begin_epoch = 0 #初始epoch\n",
    "\n",
    "    model.train() #切换到训练模式\n",
    "      \n",
    "    if not cfg.distribution:\n",
    "        #device = torch.device(cfg.device) #选择设备\n",
    "        try: #有gpu\n",
    "            #model.cuda(device) #设备选择\n",
    "            model.cuda()\n",
    "            gpu = True #是否有gpu\n",
    "            print('Gpu is used')\n",
    "        except:#不用gpu\n",
    "            gpu = False\n",
    "            print('Cpu is used')\n",
    "    else:\n",
    "        gpu = True #是否有gpu\n",
    "        print('Gpu is used')\n",
    "    \n",
    "    if cfg.pretrain: #如果预训练\n",
    "        model_info = torch.load(os.path.join(cfg.pretrain, 'model_{}_state.pkl'.format(cfg.model_name)))\n",
    "        \n",
    "    criterion = torch.nn.CrossEntropyLoss() #损失函数方法：交叉熵（自带softmax）\n",
    "    alpha = cfg.alpha if not cfg.pretrain else model_info['alpha'] #初始学习率，有预处理以预处理为准\n",
    "    optimizer = torch.optim.SGD(model.parameters(), momentum = cfg.momentum, lr = alpha, weight_decay = cfg.weight_decay) #迭代方法SGD\n",
    "                                                           #动量              初始学习率            权重衰减趋势\n",
    "    #optimizer = torch.optim.Adam(model.parameters(), lr = 0.001, betas = (0.9, 0.999), eps = 1e-8, weight_decay = cfg.weight_decay) #迭代方法Adam\n",
    "                                                       #学习率      梯度及梯度平方系数   分母防零修正           权重衰减系数\n",
    "                                                       \n",
    "    #scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max = 10) #学习率衰减(余弦退火)\n",
    "                                                        #0, T_max下降，T_max到2 * T_max上升\n",
    "    #scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer,lr_lambda = lambda step:np.sin(step) / step) #自己设定,函数输入为步数\n",
    "                                                                    #自己设定函数\n",
    "    #scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones = [20, 80], gamma = 0.9) #分段式衰减\n",
    "                                                                #设定变化点，遇到该点变化  衰减系数\n",
    "    #scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, gamma = 0.99) #指数衰减，每个epoch\n",
    "                                                                   #衰减系数\n",
    "    #scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode = 'min', factor = cfg.lr_decay, patience = 5, verbose = False, threshold = 0.0001, threshold_mode = 'rel', cooldown = 0, min_lr = 0, eps = 1e-08) #自适应\n",
    "                                                                     #检测loss减小            衰减系数       容忍次数        是否print         变化阈值范围        rel比例 abs值           冷却时间      最小lr  效果较差不变                                  \n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size = cfg.lr_step, gamma = cfg.lr_decay) #学习率线性衰减\n",
    "                                                                #衰减步长         衰减系数 lr *= lr_decay\n",
    "        \n",
    "    if gpu:\n",
    "        model.cuda()\n",
    "        model, optimizer = amp.initialize(model, optimizer, opt_level = \"O1\", verbosity = 0) #混合精度模型\n",
    "                                              #Oo fp32, O1混合, O2几乎fp16, O3 fp16   \n",
    "        \n",
    "    if not cfg.pretrain: #如果预训练\n",
    "        model.apply(initialize_weights) #模型初始化，内置初始化，均匀分布\n",
    "\n",
    "    if cfg.distribution:\n",
    "        model = torch.nn.DataParallel(model, device_ids = list(cfg.distribution))\n",
    "        \n",
    "    if cfg.pretrain: #如果预训练\n",
    "        model.load_state_dict(model_info['state_dict']) #加载训练出的模型\n",
    "        begin_epoch = model_info['epoch'] + 1   \n",
    "        if not cfg.mix_up:\n",
    "            best_correct = model_info['best_correct']\n",
    "        train_loss = model_info['train_loss']\n",
    "    else:\n",
    "        best_correct = 0 #最优的正确数\n",
    "        train_loss = []\n",
    "    \n",
    "    total_start_time = time.time() #记录时间\n",
    "    start_time = time.time() #记录时间\n",
    "    \n",
    "    for epoch in tqdm(range(begin_epoch, cfg.epoch_num)): #迭代全图\n",
    "    #for epoch in range(1, cfg.epoch_num + 1): #迭代全图  \n",
    "        correct = 0 #正确的图片数量  \n",
    "        total = 0 #图片总数\n",
    "        \n",
    "        train_loss_i = 0 #第i次epoch损失\n",
    "        for batch_idx, (imgs, classes) in enumerate(trainloader): #迭代批次\n",
    "            #批数       图片    类别 \n",
    "            \n",
    "            #one-hot label 化：(交叉熵里面自动有)\n",
    "            #classes = torch.zeros(cfg.batch_size, len(cfg.classes)).scatter_(1, classes.view(len(classes),1), 1)\n",
    "                                                                   #稀疏化 维度       值                  对应标签值           \n",
    "            \n",
    "            if cfg.mix_up:  #mix_up策略\n",
    "                imgs, classes_a, classes_b, lam = mix_up_data(imgs, classes)  #非one-hot label数据mix-up\n",
    "                if gpu: #用gpu\n",
    "                    imgs, classes_a, classes_b = imgs.cuda(), classes_a.cuda(), classes_b.cuda() #将数据移到GPU上          \n",
    "                inputs, targets_a, targets_b = Variable(imgs), Variable(classes_a),  Variable(classes_b) #变量化输入x,y_a,y_b\n",
    "                \"\"\"\n",
    "                imgs, classes = mix_up_onehot_data(imgs, classes) #one-hot label数据mix-up\n",
    "                if gpu: #用gpu\n",
    "                    imgs, classes = imgs.cuda(), classes.cuda() #将数据移到GPU上\n",
    "                inputs, targets = Variable(imgs), Variable(classes)  #变量化输入x,y\n",
    "                \"\"\"\n",
    "            else: #没用mix_up策略\n",
    "                if gpu: #用gpu\n",
    "                    imgs, classes = imgs.cuda(), classes.cuda() #将数据移到GPU上\n",
    "                inputs, targets = Variable(imgs), Variable(classes)  #变量化输入x,y\n",
    "         \n",
    "            optimizer.zero_grad()   # 先将optimizer梯度先置为0\n",
    "            \n",
    "            outputs = model(inputs) #前向传播\n",
    "            #outputs = model.forward(inputs) #等价效果\n",
    "            \n",
    "            if cfg.mix_up: #如果mix_up\n",
    "                loss = lam * criterion(outputs, targets_a) + (1 - lam) * criterion(outputs, targets_b) # 计算mix-up损失函数\n",
    "            else: #如果没mix_up\n",
    "                loss = criterion(outputs, targets) #损失函数\n",
    "                \n",
    "            #loss = criterion(outputs, targets)\n",
    "            \n",
    "            if gpu:\n",
    "                with amp.scale_loss(loss, optimizer) as scaled_loss:#采用混合精度模型         \n",
    "                    scaled_loss.backward() \n",
    "            else:\n",
    "                loss.backward()  #反向传播，计算梯度\n",
    "            #loss.backward()  #反向传播，计算梯度\n",
    "            \n",
    "            optimizer.step() #更新参数\n",
    "        \n",
    "            train_loss_i += loss.data.item()#记录每次训练Loss, 必须loss.data[0]\n",
    "            \n",
    "            if not cfg.mix_up: #没有mix_up下才有中间结果\n",
    "                _, predicted = torch.max(outputs.data, dim = 1) #获得预测结果，结果为批次数据, 所以行最大(一行一个结果)\n",
    "                correct += predicted.eq(targets.data).cpu().sum().item() #计算正确的图片数，cpu上算,.tensor.item()获取值\n",
    "                \n",
    "            total += inputs.size(0)#图片数加总(size第一维为批大小), size为大小\n",
    "        \n",
    "        scheduler.step() #学习率记录step      \n",
    "        train_loss.append(train_loss_i) #记录每轮的损失函数值\n",
    "        precision = 100. * correct / total #准确率 \n",
    "    \n",
    "        if  epoch % 5 == 4: #每五次迭代            \n",
    "            end_time = time.time() #记录时间\n",
    "            \n",
    "            #展示模型训练状态\n",
    "            print(' ')\n",
    "            print('>' * 80)    \n",
    "            print('Epoch : {} - {}'.format(epoch - 3, epoch + 1))\n",
    "            print('Training_time = {} s / epoch'.format(str( (end_time - start_time) / 5 )[:8]) )\n",
    "            print('Avg_loss_function = {}'.format(np.mean(train_loss[-5:])))\n",
    "            if not cfg.mix_up:\n",
    "                print('Precision = {} %'.format(precision))            \n",
    "            print('>' * 80)\n",
    "            print(' ')\n",
    "            \n",
    "            if not cfg.mix_up and epoch / cfg.epoch_num > 0.1 and correct >= best_correct: #预热10%迭代, 更好的模型，mix_up下没法比较\n",
    "                best_correct = correct #更新最优结果\n",
    "                torch.save({'epoch': epoch, 'state_dict': model.state_dict(), 'best_correct': best_correct,\n",
    "                            'train_loss': train_loss, 'alpha': optimizer.state_dict()['param_groups'][0]['lr']}, #记录迭代次数，状态字典，最好结果, 损失函数list, 学习率\n",
    "                            os.path.join(cfg.save_path, 'model_{}_state.pkl'.format(cfg.model_name))) #最好的结果(覆盖原来的)\n",
    "            \n",
    "            if cfg.mix_up:\n",
    "                torch.save({'epoch': epoch, 'state_dict': model.state_dict(),\n",
    "                            'train_loss': train_loss, 'alpha': optimizer.state_dict()['param_groups'][0]['lr']}, #记录迭代次数，状态字典，最好结果, 损失函数list, 学习率\n",
    "                            os.path.join(cfg.save_path, 'model_{}_state.pkl'.format(cfg.model_name)))\n",
    "                \n",
    "                #torch.save(model.state_dict(), os.path.join(cfg.save_path, 'model_{}_state.pkl'.format(cfg.model_name))) #最好的结果(覆盖原来的)\n",
    "                #保存中间最好的模型(以后可以再训练) 保存模型所有信息，读取时要载入框架\n",
    "                #torch.save(model, './model_{}.pkl'.format(cfg.model_name)) #保存模型信息，读取时直接读取 等价\n",
    "\n",
    "            start_time = time.time() #更新时间\n",
    "            \n",
    "        torch.cuda.empty_cache() #清理显存\n",
    "        \n",
    "    if not os.path.exists(os.path.join(cfg.save_path, 'model_{}_state.pkl'.format(cfg.model_name))): #mix_up下 或者没更好结果 下保存最后结果\n",
    "        torch.save({'epoch': epoch, 'state_dict': model.state_dict(), 'best_correct': best_correct, \n",
    "                    'train_loss': train_loss, 'alpha': optimizer.state_dict()['param_groups'][0]['lr']}, #记录迭代次数，状态字典，最好结果, 损失函数list, 学习率\n",
    "                    os.path.join(cfg.save_path, 'model_{}_state.pkl'.format(cfg.model_name))) #最好的结果(覆盖原来的)\n",
    " \n",
    "    total_end_time = time.time() #记录时间           \n",
    "    \n",
    "    print('Training time = {} s / epoch'.format( str( (total_end_time - total_start_time) / cfg.epoch_num )[:8] ) )\n",
    "    print(' ')\n",
    "    print('Finish train')\n",
    "    print('>' * 80)    \n",
    "    print(' ')\n",
    "    print(' ')\n",
    "    \n",
    "    return train_loss\n",
    "\n",
    "    \n",
    "#模型测试\n",
    "def test(testloader, cfg):\n",
    "    \"\"\"\n",
    "    :param: testloader 测试数据loader\n",
    "    :param: cfg 配置文件\n",
    "    return: precision 准确率\n",
    "    \"\"\"\n",
    "    print('>' * 80)\n",
    "    print('Begin test')\n",
    "    print(' ')\n",
    "\n",
    "    #载入模型结构   \n",
    "    model = get_model(cfg.model_name, cfg.classes, attention = cfg.attention) #根据模型名载入模型\n",
    "    if cfg.distribution:\n",
    "        model = torch.nn.DataParallel(model, device_ids = list(cfg.distribution))\n",
    "    model_info = torch.load(os.path.join(cfg.save_path, 'model_{}_state.pkl'.format(cfg.model_name))) #获取字典\n",
    "    plt.plot(model_info['train_loss'] + [model_info['train_loss'][-1]] * 5)\n",
    "    model.load_state_dict(model_info['state_dict']) #加载训练出的模型\n",
    "    \n",
    "    #model.load_state_dict(torch.load(os.path.join(cfg.save_path, 'model_{}_state.pkl'.format(cfg.model_name)))) #加载训练出的模型\n",
    "    #model = torch.load(r'./model_{}.pkl'.format(cfg.model_name)) 等价\n",
    "    \n",
    "    model.eval() #测试，不改变权重\n",
    "    \n",
    "    #test_list = pd.read_json(r'./test_list.json', orient = 'index')\n",
    "    #print(test_list)\n",
    "    device = torch.device(cfg.device) #选择设备\n",
    "    try: #用gpu\n",
    "        model.cuda(device) #设备选择\n",
    "        gpu = True #是否有gpu\n",
    "        print('Gpu is used')\n",
    "    except:#不用gpu\n",
    "        gpu = False\n",
    "        print('Cpu is used')\n",
    "    \n",
    "    correct = 0 #正确数\n",
    "    total = 0 #图片总数\n",
    "    #wronglist = pd.DataFrame(columns = ['index', 'type', 'path']) #分错序号\n",
    "    wronglist = []\n",
    "    with torch.no_grad(): #不进行反向传播, 减少内存\n",
    "        \n",
    "        start_time = time.time() #记录时间\n",
    "        \n",
    "        for idx, (imgs, classes) in enumerate(testloader): #遍历图片\n",
    "           #索引  图片   类别\n",
    "           if gpu:#用gpu\n",
    "               imgs, classes = imgs.cuda(), classes.cuda()   # 将数据移到GPU上\n",
    "           inputs, targets = Variable(imgs), Variable(classes) #变量化输入x,y\n",
    "           \n",
    "           outputs = model(inputs) #运行模型(获得结果)\n",
    "           \n",
    "           _, predicted = torch.max(outputs.data, dim = 1) #获得预测结果，结果为批次数据, 所以行最大(一行一个结果)\n",
    "           correct += predicted.eq(targets.data).cpu().sum().item() #正确数,cpu上算\n",
    "                   \n",
    "           if predicted.eq(targets.data).cpu().sum().item() != 1: #如果判断错\n",
    "               wronglist.append((idx, classes))\n",
    "               \n",
    "           total += targets.size(0) #图片数加总(size第一维为批大小), size为大小\n",
    "\n",
    "        end_time = time.time()\n",
    "     \n",
    "        precision = 100. * correct / total #准确率\n",
    "        \n",
    "        torch.cuda.empty_cache() #清理显存\n",
    "    \n",
    "    #json_wrong = wronglist.to_json(orient = 'index')\n",
    "    #with open(r'./wronglist.json', 'w') as jsonFile:\n",
    "         #jsonFile.write(json_wrong)\n",
    "    \n",
    "    print('Infering time = {} s / pic'.format( str( (end_time - start_time) / total )[:8] ) )\n",
    "    print(' ')\n",
    "    print('Finish test')\n",
    "    print('>' * 80)    \n",
    "    print(' ')\n",
    "    print(' ')\n",
    "    \n",
    "    print('Test Precision = {} %'.format(precision))   \n",
    "    \n",
    "    return precision, wronglist\n",
    "\n",
    "\n",
    "def main(config_path):\n",
    "    \"\"\"\n",
    "    主函数, 完成数据载入和模型训练 + 测试\n",
    "    :param: config_path config路径\n",
    "    return: train_loss,        precision,       wronglist       \n",
    "            各epcoh下训练损失   测试准确性       错判断序号列表\n",
    "    \"\"\"\n",
    "    torch.backends.cudnn.benchmark = True \n",
    "    cfg = Config(config_path) #获取配置文件\n",
    "    #if cfg.distribution:\n",
    "        #torch.distributed.init_process_group(backend = 'nccl', init_method = ,world_size = cfg.distribution)\n",
    "    trainloader, testloader, data_ok = get_data(cfg) #获取数据并进行数据预处理和增强\n",
    "    if data_ok:\n",
    "        train_loss = train(trainloader, cfg) #模型训练\n",
    "        precision, wronglist = test(testloader, cfg) #模型测试\n",
    "    \n",
    "        return train_loss, precision, wronglist \n",
    "    \n",
    "    else:\n",
    "        return None, None, None\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":        \n",
    "    train_loss, precision, wronglist = main(r'./config.yml')\n",
    "    while True:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(18, tensor([0], device='cuda:0')),\n",
       " (45, tensor([0], device='cuda:0')),\n",
       " (121, tensor([0], device='cuda:0')),\n",
       " (122, tensor([0], device='cuda:0')),\n",
       " (131, tensor([0], device='cuda:0')),\n",
       " (154, tensor([0], device='cuda:0')),\n",
       " (165, tensor([0], device='cuda:0')),\n",
       " (213, tensor([0], device='cuda:0')),\n",
       " (261, tensor([0], device='cuda:0')),\n",
       " (327, tensor([0], device='cuda:0')),\n",
       " (347, tensor([0], device='cuda:0')),\n",
       " (354, tensor([0], device='cuda:0')),\n",
       " (360, tensor([0], device='cuda:0')),\n",
       " (361, tensor([0], device='cuda:0')),\n",
       " (366, tensor([0], device='cuda:0')),\n",
       " (368, tensor([0], device='cuda:0')),\n",
       " (369, tensor([0], device='cuda:0')),\n",
       " (372, tensor([0], device='cuda:0')),\n",
       " (373, tensor([0], device='cuda:0')),\n",
       " (374, tensor([0], device='cuda:0')),\n",
       " (375, tensor([0], device='cuda:0')),\n",
       " (382, tensor([0], device='cuda:0')),\n",
       " (384, tensor([0], device='cuda:0')),\n",
       " (387, tensor([0], device='cuda:0')),\n",
       " (389, tensor([0], device='cuda:0')),\n",
       " (391, tensor([0], device='cuda:0')),\n",
       " (393, tensor([0], device='cuda:0')),\n",
       " (394, tensor([0], device='cuda:0')),\n",
       " (395, tensor([0], device='cuda:0')),\n",
       " (397, tensor([0], device='cuda:0')),\n",
       " (404, tensor([0], device='cuda:0')),\n",
       " (409, tensor([0], device='cuda:0')),\n",
       " (410, tensor([0], device='cuda:0')),\n",
       " (418, tensor([0], device='cuda:0')),\n",
       " (437, tensor([0], device='cuda:0')),\n",
       " (451, tensor([0], device='cuda:0')),\n",
       " (472, tensor([0], device='cuda:0')),\n",
       " (473, tensor([0], device='cuda:0')),\n",
       " (474, tensor([0], device='cuda:0')),\n",
       " (475, tensor([0], device='cuda:0')),\n",
       " (477, tensor([0], device='cuda:0')),\n",
       " (489, tensor([0], device='cuda:0')),\n",
       " (522, tensor([0], device='cuda:0')),\n",
       " (534, tensor([0], device='cuda:0')),\n",
       " (566, tensor([0], device='cuda:0')),\n",
       " (583, tensor([0], device='cuda:0')),\n",
       " (587, tensor([0], device='cuda:0')),\n",
       " (592, tensor([0], device='cuda:0')),\n",
       " (593, tensor([0], device='cuda:0')),\n",
       " (594, tensor([0], device='cuda:0')),\n",
       " (600, tensor([0], device='cuda:0')),\n",
       " (607, tensor([0], device='cuda:0')),\n",
       " (626, tensor([0], device='cuda:0')),\n",
       " (637, tensor([0], device='cuda:0')),\n",
       " (639, tensor([0], device='cuda:0')),\n",
       " (643, tensor([0], device='cuda:0')),\n",
       " (677, tensor([1], device='cuda:0')),\n",
       " (679, tensor([1], device='cuda:0')),\n",
       " (681, tensor([1], device='cuda:0')),\n",
       " (683, tensor([1], device='cuda:0')),\n",
       " (734, tensor([1], device='cuda:0')),\n",
       " (753, tensor([1], device='cuda:0')),\n",
       " (754, tensor([1], device='cuda:0')),\n",
       " (756, tensor([1], device='cuda:0')),\n",
       " (779, tensor([1], device='cuda:0')),\n",
       " (781, tensor([1], device='cuda:0'))]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wronglist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
